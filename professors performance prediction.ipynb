{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Professors Performance Analysis using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_PROFESSOR</th>\n",
       "      <th>TT</th>\n",
       "      <th>TX_RESP_Q001</th>\n",
       "      <th>TX_RESP_Q002</th>\n",
       "      <th>TX_RESP_Q004</th>\n",
       "      <th>TX_RESP_Q010</th>\n",
       "      <th>TX_RESP_Q005</th>\n",
       "      <th>TX_RESP_Q008</th>\n",
       "      <th>TX_RESP_Q009</th>\n",
       "      <th>TX_RESP_Q010.1</th>\n",
       "      <th>TX_RESP_Q013</th>\n",
       "      <th>TX_RESP_Q014</th>\n",
       "      <th>TX_RESP_Q015</th>\n",
       "      <th>TX_RESP_Q016</th>\n",
       "      <th>TX_RESP_Q017</th>\n",
       "      <th>TX_RESP_Q018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017176053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017282685</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017289663</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017055337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017055338</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CO_PROFESSOR  TT  TX_RESP_Q001  TX_RESP_Q002  TX_RESP_Q004  TX_RESP_Q010  \\\n",
       "0    2017176053   1             1             4             3             4   \n",
       "1    2017282685   1             1             4             3             4   \n",
       "2    2017289663   1             1             4             3             4   \n",
       "3    2017055337   1             1             4             3             4   \n",
       "4    2017055338   1             1             1             2             6   \n",
       "\n",
       "   TX_RESP_Q005  TX_RESP_Q008  TX_RESP_Q009  TX_RESP_Q010.1  TX_RESP_Q013  \\\n",
       "0             4             2             2               4             3   \n",
       "1             4             2             2               4             3   \n",
       "2             4             2             2               4             3   \n",
       "3             4             2             2               4             3   \n",
       "4             3             0             0               6             5   \n",
       "\n",
       "   TX_RESP_Q014  TX_RESP_Q015  TX_RESP_Q016  TX_RESP_Q017  TX_RESP_Q018  \n",
       "0             2             3             1             0             1  \n",
       "1             2             3             1             0             1  \n",
       "2             2             3             1             0             1  \n",
       "3             2             3             1             0             1  \n",
       "4             2             1             0             0             2  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"f:Work/professors_performance.csv\", header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TX_RESP_Q001</th>\n",
       "      <th>TX_RESP_Q002</th>\n",
       "      <th>TX_RESP_Q004</th>\n",
       "      <th>TX_RESP_Q010</th>\n",
       "      <th>TX_RESP_Q005</th>\n",
       "      <th>TX_RESP_Q008</th>\n",
       "      <th>TX_RESP_Q009</th>\n",
       "      <th>TX_RESP_Q013</th>\n",
       "      <th>TX_RESP_Q014</th>\n",
       "      <th>TX_RESP_Q015</th>\n",
       "      <th>TX_RESP_Q016</th>\n",
       "      <th>TX_RESP_Q017</th>\n",
       "      <th>TX_RESP_Q018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TX_RESP_Q001  TX_RESP_Q002  TX_RESP_Q004  TX_RESP_Q010  TX_RESP_Q005  \\\n",
       "0             1             4             3             4             4   \n",
       "1             1             4             3             4             4   \n",
       "2             1             4             3             4             4   \n",
       "3             1             4             3             4             4   \n",
       "4             1             1             2             6             3   \n",
       "\n",
       "   TX_RESP_Q008  TX_RESP_Q009  TX_RESP_Q013  TX_RESP_Q014  TX_RESP_Q015  \\\n",
       "0             2             2             3             2             3   \n",
       "1             2             2             3             2             3   \n",
       "2             2             2             3             2             3   \n",
       "3             2             2             3             2             3   \n",
       "4             0             0             5             2             1   \n",
       "\n",
       "   TX_RESP_Q016  TX_RESP_Q017  TX_RESP_Q018  \n",
       "0             1             0             1  \n",
       "1             1             0             1  \n",
       "2             1             0             1  \n",
       "3             1             0             1  \n",
       "4             0             0             2  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df.drop(['TX_RESP_Q010.1','CO_PROFESSOR', 'TT'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6844, 13)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6844 entries, 0 to 6843\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   TX_RESP_Q001  6844 non-null   int64\n",
      " 1   TX_RESP_Q002  6844 non-null   int64\n",
      " 2   TX_RESP_Q004  6844 non-null   int64\n",
      " 3   TX_RESP_Q010  6844 non-null   int64\n",
      " 4   TX_RESP_Q005  6844 non-null   int64\n",
      " 5   TX_RESP_Q008  6844 non-null   int64\n",
      " 6   TX_RESP_Q009  6844 non-null   int64\n",
      " 7   TX_RESP_Q013  6844 non-null   int64\n",
      " 8   TX_RESP_Q014  6844 non-null   int64\n",
      " 9   TX_RESP_Q015  6844 non-null   int64\n",
      " 10  TX_RESP_Q016  6844 non-null   int64\n",
      " 11  TX_RESP_Q017  6844 non-null   int64\n",
      " 12  TX_RESP_Q018  6844 non-null   int64\n",
      "dtypes: int64(13)\n",
      "memory usage: 695.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       TX_RESP_Q001  TX_RESP_Q002  TX_RESP_Q004  TX_RESP_Q010  TX_RESP_Q005  \\\n",
       "0                1             4             3             4             4   \n",
       "1                1             4             3             4             4   \n",
       "2                1             4             3             4             4   \n",
       "3                1             4             3             4             4   \n",
       "4                1             1             2             6             3   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "6839             0             2             2             3             4   \n",
       "6840             0             2             2             3             4   \n",
       "6841             0             2             2             3             4   \n",
       "6842             0             2             2             3             4   \n",
       "6843             1             4             3             2             4   \n",
       "\n",
       "      TX_RESP_Q008  TX_RESP_Q009  TX_RESP_Q013  TX_RESP_Q014  TX_RESP_Q015  \\\n",
       "0                2             2             3             2             3   \n",
       "1                2             2             3             2             3   \n",
       "2                2             2             3             2             3   \n",
       "3                2             2             3             2             3   \n",
       "4                0             0             5             2             1   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "6839             1             0             3             6             6   \n",
       "6840             1             0             3             6             6   \n",
       "6841             1             0             3             6             6   \n",
       "6842             1             0             3             6             6   \n",
       "6843             2             1             2             6             5   \n",
       "\n",
       "      TX_RESP_Q016  TX_RESP_Q017  TX_RESP_Q018  \n",
       "0                1             0             1  \n",
       "1                1             0             1  \n",
       "2                1             0             1  \n",
       "3                1             0             1  \n",
       "4                0             0             2  \n",
       "...            ...           ...           ...  \n",
       "6839             1             0             1  \n",
       "6840             1             0             1  \n",
       "6841             1             0             1  \n",
       "6842             1             0             1  \n",
       "6843             1             0             2  \n",
       "\n",
       "[6844 rows x 13 columns]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 3, ..., 1, 0, 1],\n",
       "       [1, 4, 3, ..., 1, 0, 1],\n",
       "       [1, 4, 3, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 2, 2, ..., 1, 0, 1],\n",
       "       [0, 2, 2, ..., 1, 0, 1],\n",
       "       [1, 4, 3, ..., 1, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to_numpy() will return a NumPy array and the categorical dtype will be lost\n",
    "\n",
    "X =data.to_numpy() # features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.loc[:,'TT']\n",
    "y.shape\n",
    "\n",
    "y=y.to_numpy() # label\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of input data - explanatory variable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation between training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create instant of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of ANN and its layers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Neural Network - 13 inputs and 01 output, with 2 intermediate layers (hidden)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=13, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6159/6159 [==============================] - 0s 45us/step - loss: 0.6560 - accuracy: 0.6946\n",
      "Epoch 2/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.5311 - accuracy: 0.7998\n",
      "Epoch 3/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.5051 - accuracy: 0.8079\n",
      "Epoch 4/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4942 - accuracy: 0.8079\n",
      "Epoch 5/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4870 - accuracy: 0.8084\n",
      "Epoch 6/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4823 - accuracy: 0.8084\n",
      "Epoch 7/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4788 - accuracy: 0.8084\n",
      "Epoch 8/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4758 - accuracy: 0.8084\n",
      "Epoch 9/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4735 - accuracy: 0.8084\n",
      "Epoch 10/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4715 - accuracy: 0.8084\n",
      "Epoch 11/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4692 - accuracy: 0.8084\n",
      "Epoch 12/100\n",
      "6159/6159 [==============================] - 0s 23us/step - loss: 0.4677 - accuracy: 0.8084\n",
      "Epoch 13/100\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4661 - accuracy: 0.8084\n",
      "Epoch 14/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4644 - accuracy: 0.8084\n",
      "Epoch 15/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4634 - accuracy: 0.8099\n",
      "Epoch 16/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4619 - accuracy: 0.8091\n",
      "Epoch 17/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4610 - accuracy: 0.8094\n",
      "Epoch 18/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4599 - accuracy: 0.8097\n",
      "Epoch 19/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4584 - accuracy: 0.8095\n",
      "Epoch 20/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4587 - accuracy: 0.8097\n",
      "Epoch 21/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4571 - accuracy: 0.8102\n",
      "Epoch 22/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4560 - accuracy: 0.8097\n",
      "Epoch 23/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4556 - accuracy: 0.8104\n",
      "Epoch 24/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4547 - accuracy: 0.8107\n",
      "Epoch 25/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4538 - accuracy: 0.8100\n",
      "Epoch 26/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4531 - accuracy: 0.8100\n",
      "Epoch 27/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4526 - accuracy: 0.8107\n",
      "Epoch 28/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4515 - accuracy: 0.8104\n",
      "Epoch 29/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4504 - accuracy: 0.8107\n",
      "Epoch 30/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4496 - accuracy: 0.8113\n",
      "Epoch 31/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4487 - accuracy: 0.8105\n",
      "Epoch 32/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4479 - accuracy: 0.8105\n",
      "Epoch 33/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4470 - accuracy: 0.8107\n",
      "Epoch 34/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4472 - accuracy: 0.8104\n",
      "Epoch 35/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4461 - accuracy: 0.8092\n",
      "Epoch 36/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4458 - accuracy: 0.8086\n",
      "Epoch 37/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4452 - accuracy: 0.8084\n",
      "Epoch 38/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4444 - accuracy: 0.8073\n",
      "Epoch 39/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4438 - accuracy: 0.8071\n",
      "Epoch 40/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4434 - accuracy: 0.8069\n",
      "Epoch 41/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4429 - accuracy: 0.8071\n",
      "Epoch 42/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4426 - accuracy: 0.8078\n",
      "Epoch 43/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4419 - accuracy: 0.8074\n",
      "Epoch 44/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4417 - accuracy: 0.8074\n",
      "Epoch 45/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4412 - accuracy: 0.8073\n",
      "Epoch 46/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4407 - accuracy: 0.8071\n",
      "Epoch 47/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4406 - accuracy: 0.8074\n",
      "Epoch 48/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4397 - accuracy: 0.8082\n",
      "Epoch 49/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4397 - accuracy: 0.8063\n",
      "Epoch 50/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4391 - accuracy: 0.8082\n",
      "Epoch 51/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4387 - accuracy: 0.8091\n",
      "Epoch 52/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4381 - accuracy: 0.8092\n",
      "Epoch 53/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4382 - accuracy: 0.8095\n",
      "Epoch 54/100\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4379 - accuracy: 0.8073\n",
      "Epoch 55/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4375 - accuracy: 0.8087\n",
      "Epoch 56/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4371 - accuracy: 0.8112\n",
      "Epoch 57/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4367 - accuracy: 0.8095\n",
      "Epoch 58/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4363 - accuracy: 0.8104\n",
      "Epoch 59/100\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4359 - accuracy: 0.8113\n",
      "Epoch 60/100\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4351 - accuracy: 0.8126\n",
      "Epoch 61/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4352 - accuracy: 0.8110\n",
      "Epoch 62/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4347 - accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4343 - accuracy: 0.8123\n",
      "Epoch 64/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4340 - accuracy: 0.8117\n",
      "Epoch 65/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4336 - accuracy: 0.8118\n",
      "Epoch 66/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4338 - accuracy: 0.8128\n",
      "Epoch 67/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4329 - accuracy: 0.8133\n",
      "Epoch 68/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4323 - accuracy: 0.8138\n",
      "Epoch 69/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4328 - accuracy: 0.8126\n",
      "Epoch 70/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4323 - accuracy: 0.8156\n",
      "Epoch 71/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4319 - accuracy: 0.8138\n",
      "Epoch 72/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4321 - accuracy: 0.8141\n",
      "Epoch 73/100\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4314 - accuracy: 0.8141\n",
      "Epoch 74/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4307 - accuracy: 0.8134\n",
      "Epoch 75/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4308 - accuracy: 0.8151\n",
      "Epoch 76/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4304 - accuracy: 0.8164\n",
      "Epoch 77/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4302 - accuracy: 0.8147\n",
      "Epoch 78/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4301 - accuracy: 0.8164\n",
      "Epoch 79/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4297 - accuracy: 0.8159\n",
      "Epoch 80/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4295 - accuracy: 0.8154\n",
      "Epoch 81/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4296 - accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4295 - accuracy: 0.8162\n",
      "Epoch 83/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4293 - accuracy: 0.8143\n",
      "Epoch 84/100\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4286 - accuracy: 0.8173\n",
      "Epoch 85/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4287 - accuracy: 0.8159\n",
      "Epoch 86/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4288 - accuracy: 0.8157\n",
      "Epoch 87/100\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4288 - accuracy: 0.8177\n",
      "Epoch 88/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4281 - accuracy: 0.8157\n",
      "Epoch 89/100\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4278 - accuracy: 0.8170\n",
      "Epoch 90/100\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4276 - accuracy: 0.8196\n",
      "Epoch 91/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4275 - accuracy: 0.8173\n",
      "Epoch 92/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4273 - accuracy: 0.8173\n",
      "Epoch 93/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4268 - accuracy: 0.8177\n",
      "Epoch 94/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4267 - accuracy: 0.8185\n",
      "Epoch 95/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4268 - accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4260 - accuracy: 0.8180\n",
      "Epoch 97/100\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4261 - accuracy: 0.8206\n",
      "Epoch 98/100\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4258 - accuracy: 0.8186\n",
      "Epoch 99/100\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4256 - accuracy: 0.8203\n",
      "Epoch 100/100\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4255 - accuracy: 0.8209\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Conversion of predictions\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "    \n",
    "# Conversion of the one hot encoded test label part to result\n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 96.64233576642336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6159 samples, validate on 685 samples\n",
      "Epoch 1/500\n",
      "6159/6159 [==============================] - 0s 23us/step - loss: 0.4252 - accuracy: 0.8182 - val_loss: 0.4946 - val_accuracy: 0.7942\n",
      "Epoch 2/500\n",
      "6159/6159 [==============================] - 0s 21us/step - loss: 0.4250 - accuracy: 0.8193 - val_loss: 0.4949 - val_accuracy: 0.7912\n",
      "Epoch 3/500\n",
      "6159/6159 [==============================] - 0s 23us/step - loss: 0.4252 - accuracy: 0.8177 - val_loss: 0.4970 - val_accuracy: 0.7927\n",
      "Epoch 4/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4247 - accuracy: 0.8188 - val_loss: 0.4945 - val_accuracy: 0.7898\n",
      "Epoch 5/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4239 - accuracy: 0.8190 - val_loss: 0.4944 - val_accuracy: 0.7942\n",
      "Epoch 6/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4244 - accuracy: 0.8201 - val_loss: 0.4941 - val_accuracy: 0.7854\n",
      "Epoch 7/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4234 - accuracy: 0.8201 - val_loss: 0.4977 - val_accuracy: 0.7912\n",
      "Epoch 8/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4234 - accuracy: 0.8190 - val_loss: 0.4946 - val_accuracy: 0.7883\n",
      "Epoch 9/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4229 - accuracy: 0.8211 - val_loss: 0.4939 - val_accuracy: 0.7883\n",
      "Epoch 10/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4224 - accuracy: 0.8196 - val_loss: 0.4961 - val_accuracy: 0.7869\n",
      "Epoch 11/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4226 - accuracy: 0.8190 - val_loss: 0.4938 - val_accuracy: 0.7854\n",
      "Epoch 12/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4224 - accuracy: 0.8217 - val_loss: 0.4934 - val_accuracy: 0.7839\n",
      "Epoch 13/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4220 - accuracy: 0.8209 - val_loss: 0.4943 - val_accuracy: 0.7825\n",
      "Epoch 14/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4222 - accuracy: 0.8209 - val_loss: 0.4982 - val_accuracy: 0.7839\n",
      "Epoch 15/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4214 - accuracy: 0.8208 - val_loss: 0.4928 - val_accuracy: 0.7869\n",
      "Epoch 16/500\n",
      "6159/6159 [==============================] - 0s 21us/step - loss: 0.4217 - accuracy: 0.8220 - val_loss: 0.4935 - val_accuracy: 0.7810\n",
      "Epoch 17/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4210 - accuracy: 0.8214 - val_loss: 0.4978 - val_accuracy: 0.7810\n",
      "Epoch 18/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4205 - accuracy: 0.8225 - val_loss: 0.4973 - val_accuracy: 0.7810\n",
      "Epoch 19/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4211 - accuracy: 0.8208 - val_loss: 0.4930 - val_accuracy: 0.7810\n",
      "Epoch 20/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4208 - accuracy: 0.8212 - val_loss: 0.4952 - val_accuracy: 0.7825\n",
      "Epoch 21/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4206 - accuracy: 0.8224 - val_loss: 0.4990 - val_accuracy: 0.7854\n",
      "Epoch 22/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4197 - accuracy: 0.8214 - val_loss: 0.4972 - val_accuracy: 0.7854\n",
      "Epoch 23/500\n",
      "6159/6159 [==============================] - 0s 24us/step - loss: 0.4209 - accuracy: 0.8216 - val_loss: 0.4969 - val_accuracy: 0.7825\n",
      "Epoch 24/500\n",
      "6159/6159 [==============================] - 0s 21us/step - loss: 0.4198 - accuracy: 0.8227 - val_loss: 0.4954 - val_accuracy: 0.7781\n",
      "Epoch 25/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4195 - accuracy: 0.8237 - val_loss: 0.4928 - val_accuracy: 0.7839\n",
      "Epoch 26/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4197 - accuracy: 0.8225 - val_loss: 0.4941 - val_accuracy: 0.7810\n",
      "Epoch 27/500\n",
      "6159/6159 [==============================] - 0s 23us/step - loss: 0.4194 - accuracy: 0.8229 - val_loss: 0.4954 - val_accuracy: 0.7810\n",
      "Epoch 28/500\n",
      "6159/6159 [==============================] - 0s 23us/step - loss: 0.4191 - accuracy: 0.8233 - val_loss: 0.4958 - val_accuracy: 0.7766\n",
      "Epoch 29/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4190 - accuracy: 0.8225 - val_loss: 0.4952 - val_accuracy: 0.7781\n",
      "Epoch 30/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4188 - accuracy: 0.8222 - val_loss: 0.4953 - val_accuracy: 0.7752\n",
      "Epoch 31/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4190 - accuracy: 0.8233 - val_loss: 0.4950 - val_accuracy: 0.7810\n",
      "Epoch 32/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4186 - accuracy: 0.8232 - val_loss: 0.4956 - val_accuracy: 0.7796\n",
      "Epoch 33/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4189 - accuracy: 0.8222 - val_loss: 0.4966 - val_accuracy: 0.7810\n",
      "Epoch 34/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4182 - accuracy: 0.8235 - val_loss: 0.4981 - val_accuracy: 0.7927\n",
      "Epoch 35/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4183 - accuracy: 0.8246 - val_loss: 0.4977 - val_accuracy: 0.7839\n",
      "Epoch 36/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4184 - accuracy: 0.8222 - val_loss: 0.4948 - val_accuracy: 0.7839\n",
      "Epoch 37/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4180 - accuracy: 0.8238 - val_loss: 0.4967 - val_accuracy: 0.7752\n",
      "Epoch 38/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4177 - accuracy: 0.8238 - val_loss: 0.4976 - val_accuracy: 0.7912\n",
      "Epoch 39/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4182 - accuracy: 0.8206 - val_loss: 0.4950 - val_accuracy: 0.7781\n",
      "Epoch 40/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4173 - accuracy: 0.8222 - val_loss: 0.4948 - val_accuracy: 0.7839\n",
      "Epoch 41/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4180 - accuracy: 0.8245 - val_loss: 0.4945 - val_accuracy: 0.7825\n",
      "Epoch 42/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4176 - accuracy: 0.8242 - val_loss: 0.4961 - val_accuracy: 0.7766\n",
      "Epoch 43/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4175 - accuracy: 0.8229 - val_loss: 0.4943 - val_accuracy: 0.7839\n",
      "Epoch 44/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4180 - accuracy: 0.8219 - val_loss: 0.4965 - val_accuracy: 0.7766\n",
      "Epoch 45/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4175 - accuracy: 0.8233 - val_loss: 0.4938 - val_accuracy: 0.7796\n",
      "Epoch 46/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4173 - accuracy: 0.8235 - val_loss: 0.4993 - val_accuracy: 0.7810\n",
      "Epoch 47/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4172 - accuracy: 0.8250 - val_loss: 0.4965 - val_accuracy: 0.7839\n",
      "Epoch 48/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4169 - accuracy: 0.8240 - val_loss: 0.5036 - val_accuracy: 0.7825\n",
      "Epoch 49/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4177 - accuracy: 0.8235 - val_loss: 0.4970 - val_accuracy: 0.7796\n",
      "Epoch 50/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4177 - accuracy: 0.8235 - val_loss: 0.4985 - val_accuracy: 0.7883\n",
      "Epoch 51/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4170 - accuracy: 0.8230 - val_loss: 0.4956 - val_accuracy: 0.7839\n",
      "Epoch 52/500\n",
      "6159/6159 [==============================] - 0s 28us/step - loss: 0.4166 - accuracy: 0.8238 - val_loss: 0.4984 - val_accuracy: 0.7766\n",
      "Epoch 53/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4167 - accuracy: 0.8217 - val_loss: 0.4969 - val_accuracy: 0.7898\n",
      "Epoch 54/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4159 - accuracy: 0.8232 - val_loss: 0.5030 - val_accuracy: 0.7854\n",
      "Epoch 55/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4166 - accuracy: 0.8219 - val_loss: 0.4986 - val_accuracy: 0.7825\n",
      "Epoch 56/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4162 - accuracy: 0.8232 - val_loss: 0.4953 - val_accuracy: 0.7825\n",
      "Epoch 57/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4166 - accuracy: 0.8225 - val_loss: 0.4957 - val_accuracy: 0.7766\n",
      "Epoch 58/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4168 - accuracy: 0.8222 - val_loss: 0.4973 - val_accuracy: 0.7810\n",
      "Epoch 59/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4169 - accuracy: 0.8217 - val_loss: 0.4981 - val_accuracy: 0.7752\n",
      "Epoch 60/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4160 - accuracy: 0.8222 - val_loss: 0.4959 - val_accuracy: 0.7825\n",
      "Epoch 61/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4154 - accuracy: 0.8230 - val_loss: 0.4934 - val_accuracy: 0.7752\n",
      "Epoch 62/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4165 - accuracy: 0.8220 - val_loss: 0.4962 - val_accuracy: 0.7839\n",
      "Epoch 63/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4158 - accuracy: 0.8220 - val_loss: 0.4971 - val_accuracy: 0.7854\n",
      "Epoch 64/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4158 - accuracy: 0.8229 - val_loss: 0.4954 - val_accuracy: 0.7752\n",
      "Epoch 65/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4164 - accuracy: 0.8229 - val_loss: 0.4939 - val_accuracy: 0.7839\n",
      "Epoch 66/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4157 - accuracy: 0.8232 - val_loss: 0.4958 - val_accuracy: 0.7781\n",
      "Epoch 67/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4162 - accuracy: 0.8224 - val_loss: 0.4990 - val_accuracy: 0.7854\n",
      "Epoch 68/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4155 - accuracy: 0.8227 - val_loss: 0.4958 - val_accuracy: 0.7766\n",
      "Epoch 69/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4157 - accuracy: 0.8225 - val_loss: 0.4979 - val_accuracy: 0.7825\n",
      "Epoch 70/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4157 - accuracy: 0.8214 - val_loss: 0.5008 - val_accuracy: 0.7810\n",
      "Epoch 71/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4160 - accuracy: 0.8240 - val_loss: 0.4953 - val_accuracy: 0.7796\n",
      "Epoch 72/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4151 - accuracy: 0.8217 - val_loss: 0.4938 - val_accuracy: 0.7766\n",
      "Epoch 73/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4155 - accuracy: 0.8229 - val_loss: 0.4968 - val_accuracy: 0.7825\n",
      "Epoch 74/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4155 - accuracy: 0.8206 - val_loss: 0.4959 - val_accuracy: 0.7883\n",
      "Epoch 75/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4151 - accuracy: 0.8224 - val_loss: 0.4996 - val_accuracy: 0.7810\n",
      "Epoch 76/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4149 - accuracy: 0.8222 - val_loss: 0.4978 - val_accuracy: 0.7796\n",
      "Epoch 77/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4151 - accuracy: 0.8219 - val_loss: 0.4980 - val_accuracy: 0.7810\n",
      "Epoch 78/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4147 - accuracy: 0.8233 - val_loss: 0.4997 - val_accuracy: 0.7825\n",
      "Epoch 79/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4153 - accuracy: 0.8214 - val_loss: 0.4974 - val_accuracy: 0.7869\n",
      "Epoch 80/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4148 - accuracy: 0.8208 - val_loss: 0.4996 - val_accuracy: 0.7839\n",
      "Epoch 81/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4148 - accuracy: 0.8227 - val_loss: 0.4958 - val_accuracy: 0.7839\n",
      "Epoch 82/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4148 - accuracy: 0.8243 - val_loss: 0.4968 - val_accuracy: 0.7839\n",
      "Epoch 83/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4158 - accuracy: 0.8204 - val_loss: 0.4995 - val_accuracy: 0.7839\n",
      "Epoch 84/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4146 - accuracy: 0.8229 - val_loss: 0.4958 - val_accuracy: 0.7839\n",
      "Epoch 85/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4148 - accuracy: 0.8232 - val_loss: 0.4968 - val_accuracy: 0.7839\n",
      "Epoch 86/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4146 - accuracy: 0.8203 - val_loss: 0.5019 - val_accuracy: 0.7854\n",
      "Epoch 87/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4150 - accuracy: 0.8203 - val_loss: 0.4996 - val_accuracy: 0.7766\n",
      "Epoch 88/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4146 - accuracy: 0.8216 - val_loss: 0.5000 - val_accuracy: 0.7810\n",
      "Epoch 89/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4151 - accuracy: 0.8219 - val_loss: 0.4973 - val_accuracy: 0.7869\n",
      "Epoch 90/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4145 - accuracy: 0.8233 - val_loss: 0.4978 - val_accuracy: 0.7825\n",
      "Epoch 91/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4148 - accuracy: 0.8229 - val_loss: 0.4994 - val_accuracy: 0.7781\n",
      "Epoch 92/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4144 - accuracy: 0.8211 - val_loss: 0.4986 - val_accuracy: 0.7839\n",
      "Epoch 93/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4144 - accuracy: 0.8220 - val_loss: 0.4972 - val_accuracy: 0.7796\n",
      "Epoch 94/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4141 - accuracy: 0.8216 - val_loss: 0.4981 - val_accuracy: 0.7810\n",
      "Epoch 95/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4143 - accuracy: 0.8214 - val_loss: 0.4944 - val_accuracy: 0.7810\n",
      "Epoch 96/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4148 - accuracy: 0.8203 - val_loss: 0.4963 - val_accuracy: 0.7869\n",
      "Epoch 97/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4140 - accuracy: 0.8216 - val_loss: 0.4956 - val_accuracy: 0.7854\n",
      "Epoch 98/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4142 - accuracy: 0.8216 - val_loss: 0.4973 - val_accuracy: 0.7912\n",
      "Epoch 99/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4140 - accuracy: 0.8222 - val_loss: 0.4986 - val_accuracy: 0.7898\n",
      "Epoch 100/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4140 - accuracy: 0.8209 - val_loss: 0.4958 - val_accuracy: 0.7839\n",
      "Epoch 101/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4137 - accuracy: 0.8232 - val_loss: 0.4970 - val_accuracy: 0.7854\n",
      "Epoch 102/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4139 - accuracy: 0.8227 - val_loss: 0.4963 - val_accuracy: 0.7825\n",
      "Epoch 103/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4138 - accuracy: 0.8229 - val_loss: 0.4968 - val_accuracy: 0.7883\n",
      "Epoch 104/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4134 - accuracy: 0.8230 - val_loss: 0.4993 - val_accuracy: 0.7839\n",
      "Epoch 105/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4141 - accuracy: 0.8193 - val_loss: 0.4958 - val_accuracy: 0.7825\n",
      "Epoch 106/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4134 - accuracy: 0.8214 - val_loss: 0.4969 - val_accuracy: 0.7839\n",
      "Epoch 107/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4135 - accuracy: 0.8216 - val_loss: 0.4973 - val_accuracy: 0.7854\n",
      "Epoch 108/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4132 - accuracy: 0.8217 - val_loss: 0.4985 - val_accuracy: 0.7854\n",
      "Epoch 109/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4131 - accuracy: 0.8225 - val_loss: 0.4951 - val_accuracy: 0.7825\n",
      "Epoch 110/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4140 - accuracy: 0.8230 - val_loss: 0.4941 - val_accuracy: 0.7854\n",
      "Epoch 111/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4134 - accuracy: 0.8227 - val_loss: 0.4959 - val_accuracy: 0.7839\n",
      "Epoch 112/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4135 - accuracy: 0.8229 - val_loss: 0.4950 - val_accuracy: 0.7854\n",
      "Epoch 113/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4134 - accuracy: 0.8230 - val_loss: 0.4966 - val_accuracy: 0.7854\n",
      "Epoch 114/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4134 - accuracy: 0.8232 - val_loss: 0.4938 - val_accuracy: 0.7869\n",
      "Epoch 115/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4133 - accuracy: 0.8242 - val_loss: 0.4967 - val_accuracy: 0.7854\n",
      "Epoch 116/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4133 - accuracy: 0.8216 - val_loss: 0.4989 - val_accuracy: 0.7869\n",
      "Epoch 117/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4129 - accuracy: 0.8230 - val_loss: 0.4954 - val_accuracy: 0.7854\n",
      "Epoch 118/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4131 - accuracy: 0.8214 - val_loss: 0.4952 - val_accuracy: 0.7825\n",
      "Epoch 119/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4135 - accuracy: 0.8225 - val_loss: 0.4951 - val_accuracy: 0.7854\n",
      "Epoch 120/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4134 - accuracy: 0.8212 - val_loss: 0.5018 - val_accuracy: 0.7825\n",
      "Epoch 121/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4137 - accuracy: 0.8212 - val_loss: 0.4947 - val_accuracy: 0.7825\n",
      "Epoch 122/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4128 - accuracy: 0.8222 - val_loss: 0.4999 - val_accuracy: 0.7752\n",
      "Epoch 123/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4125 - accuracy: 0.8246 - val_loss: 0.4998 - val_accuracy: 0.7839\n",
      "Epoch 124/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4130 - accuracy: 0.8235 - val_loss: 0.4938 - val_accuracy: 0.7839\n",
      "Epoch 125/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4128 - accuracy: 0.8229 - val_loss: 0.4977 - val_accuracy: 0.7825\n",
      "Epoch 126/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4129 - accuracy: 0.8242 - val_loss: 0.4961 - val_accuracy: 0.7839\n",
      "Epoch 127/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4125 - accuracy: 0.8211 - val_loss: 0.4988 - val_accuracy: 0.7869\n",
      "Epoch 128/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4140 - accuracy: 0.8214 - val_loss: 0.4962 - val_accuracy: 0.7825\n",
      "Epoch 129/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4130 - accuracy: 0.8230 - val_loss: 0.4969 - val_accuracy: 0.7854\n",
      "Epoch 130/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4131 - accuracy: 0.8233 - val_loss: 0.4977 - val_accuracy: 0.7825\n",
      "Epoch 131/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4132 - accuracy: 0.8224 - val_loss: 0.5010 - val_accuracy: 0.7839\n",
      "Epoch 132/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4125 - accuracy: 0.8216 - val_loss: 0.5012 - val_accuracy: 0.7825\n",
      "Epoch 133/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4126 - accuracy: 0.8233 - val_loss: 0.5014 - val_accuracy: 0.7781\n",
      "Epoch 134/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4125 - accuracy: 0.8222 - val_loss: 0.4963 - val_accuracy: 0.7839\n",
      "Epoch 135/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4125 - accuracy: 0.8227 - val_loss: 0.4958 - val_accuracy: 0.7869\n",
      "Epoch 136/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4129 - accuracy: 0.8232 - val_loss: 0.4958 - val_accuracy: 0.7839\n",
      "Epoch 137/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4122 - accuracy: 0.8233 - val_loss: 0.4977 - val_accuracy: 0.7883\n",
      "Epoch 138/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4123 - accuracy: 0.8230 - val_loss: 0.4962 - val_accuracy: 0.7810\n",
      "Epoch 139/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4126 - accuracy: 0.8214 - val_loss: 0.5004 - val_accuracy: 0.7869\n",
      "Epoch 140/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4127 - accuracy: 0.8222 - val_loss: 0.4945 - val_accuracy: 0.7796\n",
      "Epoch 141/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4122 - accuracy: 0.8224 - val_loss: 0.4960 - val_accuracy: 0.7796\n",
      "Epoch 142/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4119 - accuracy: 0.8246 - val_loss: 0.4958 - val_accuracy: 0.7825\n",
      "Epoch 143/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4121 - accuracy: 0.8217 - val_loss: 0.4955 - val_accuracy: 0.7869\n",
      "Epoch 144/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4121 - accuracy: 0.8216 - val_loss: 0.4996 - val_accuracy: 0.7825\n",
      "Epoch 145/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4120 - accuracy: 0.8242 - val_loss: 0.4934 - val_accuracy: 0.7796\n",
      "Epoch 146/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4119 - accuracy: 0.8232 - val_loss: 0.4949 - val_accuracy: 0.7839\n",
      "Epoch 147/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4127 - accuracy: 0.8245 - val_loss: 0.4956 - val_accuracy: 0.7839\n",
      "Epoch 148/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4113 - accuracy: 0.8225 - val_loss: 0.5034 - val_accuracy: 0.7810\n",
      "Epoch 149/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4126 - accuracy: 0.8204 - val_loss: 0.4944 - val_accuracy: 0.7839\n",
      "Epoch 150/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4121 - accuracy: 0.8245 - val_loss: 0.4946 - val_accuracy: 0.7869\n",
      "Epoch 151/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4127 - accuracy: 0.8224 - val_loss: 0.4957 - val_accuracy: 0.7810\n",
      "Epoch 152/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4117 - accuracy: 0.8227 - val_loss: 0.4962 - val_accuracy: 0.7839\n",
      "Epoch 153/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4116 - accuracy: 0.8225 - val_loss: 0.4977 - val_accuracy: 0.7869\n",
      "Epoch 154/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4126 - accuracy: 0.8208 - val_loss: 0.4971 - val_accuracy: 0.7796\n",
      "Epoch 155/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4121 - accuracy: 0.8237 - val_loss: 0.4980 - val_accuracy: 0.7854\n",
      "Epoch 156/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4113 - accuracy: 0.8243 - val_loss: 0.4952 - val_accuracy: 0.7825\n",
      "Epoch 157/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4124 - accuracy: 0.8225 - val_loss: 0.4967 - val_accuracy: 0.7810\n",
      "Epoch 158/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4115 - accuracy: 0.8229 - val_loss: 0.4942 - val_accuracy: 0.7869\n",
      "Epoch 159/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4116 - accuracy: 0.8232 - val_loss: 0.4953 - val_accuracy: 0.7810\n",
      "Epoch 160/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4116 - accuracy: 0.8235 - val_loss: 0.4942 - val_accuracy: 0.7839\n",
      "Epoch 161/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4121 - accuracy: 0.8243 - val_loss: 0.4957 - val_accuracy: 0.7810\n",
      "Epoch 162/500\n",
      "6159/6159 [==============================] - 0s 21us/step - loss: 0.4113 - accuracy: 0.8219 - val_loss: 0.4959 - val_accuracy: 0.7883\n",
      "Epoch 163/500\n",
      "6159/6159 [==============================] - 0s 32us/step - loss: 0.4112 - accuracy: 0.8224 - val_loss: 0.4974 - val_accuracy: 0.7825\n",
      "Epoch 164/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4118 - accuracy: 0.8240 - val_loss: 0.4963 - val_accuracy: 0.7796\n",
      "Epoch 165/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4116 - accuracy: 0.8220 - val_loss: 0.4985 - val_accuracy: 0.7825\n",
      "Epoch 166/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4116 - accuracy: 0.8240 - val_loss: 0.5007 - val_accuracy: 0.7854\n",
      "Epoch 167/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4110 - accuracy: 0.8235 - val_loss: 0.4941 - val_accuracy: 0.7810\n",
      "Epoch 168/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4106 - accuracy: 0.8237 - val_loss: 0.4991 - val_accuracy: 0.7781\n",
      "Epoch 169/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4108 - accuracy: 0.8219 - val_loss: 0.4945 - val_accuracy: 0.7737\n",
      "Epoch 170/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4107 - accuracy: 0.8220 - val_loss: 0.4937 - val_accuracy: 0.7854\n",
      "Epoch 171/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4118 - accuracy: 0.8238 - val_loss: 0.4972 - val_accuracy: 0.7883\n",
      "Epoch 172/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4111 - accuracy: 0.8238 - val_loss: 0.4954 - val_accuracy: 0.7839\n",
      "Epoch 173/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4109 - accuracy: 0.8222 - val_loss: 0.4968 - val_accuracy: 0.7825\n",
      "Epoch 174/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4114 - accuracy: 0.8232 - val_loss: 0.4965 - val_accuracy: 0.7869\n",
      "Epoch 175/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4103 - accuracy: 0.8227 - val_loss: 0.5006 - val_accuracy: 0.7883\n",
      "Epoch 176/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4116 - accuracy: 0.8214 - val_loss: 0.4979 - val_accuracy: 0.7810\n",
      "Epoch 177/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4104 - accuracy: 0.8219 - val_loss: 0.5013 - val_accuracy: 0.7883\n",
      "Epoch 178/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4109 - accuracy: 0.8219 - val_loss: 0.4971 - val_accuracy: 0.7825\n",
      "Epoch 179/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4107 - accuracy: 0.8250 - val_loss: 0.4943 - val_accuracy: 0.7839\n",
      "Epoch 180/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4112 - accuracy: 0.8220 - val_loss: 0.4987 - val_accuracy: 0.7796\n",
      "Epoch 181/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4104 - accuracy: 0.8233 - val_loss: 0.4941 - val_accuracy: 0.7752\n",
      "Epoch 182/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4104 - accuracy: 0.8235 - val_loss: 0.4996 - val_accuracy: 0.7839\n",
      "Epoch 183/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4106 - accuracy: 0.8222 - val_loss: 0.4996 - val_accuracy: 0.7825\n",
      "Epoch 184/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4107 - accuracy: 0.8237 - val_loss: 0.4978 - val_accuracy: 0.7839\n",
      "Epoch 185/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4111 - accuracy: 0.8230 - val_loss: 0.4972 - val_accuracy: 0.7796\n",
      "Epoch 186/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4111 - accuracy: 0.8222 - val_loss: 0.4978 - val_accuracy: 0.7869\n",
      "Epoch 187/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4102 - accuracy: 0.8208 - val_loss: 0.4964 - val_accuracy: 0.7839\n",
      "Epoch 188/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4107 - accuracy: 0.8235 - val_loss: 0.4960 - val_accuracy: 0.7854\n",
      "Epoch 189/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4103 - accuracy: 0.8219 - val_loss: 0.4954 - val_accuracy: 0.7854\n",
      "Epoch 190/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4111 - accuracy: 0.8235 - val_loss: 0.4972 - val_accuracy: 0.7839\n",
      "Epoch 191/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4100 - accuracy: 0.8232 - val_loss: 0.4942 - val_accuracy: 0.7796\n",
      "Epoch 192/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4107 - accuracy: 0.8225 - val_loss: 0.4966 - val_accuracy: 0.7898\n",
      "Epoch 193/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4103 - accuracy: 0.8224 - val_loss: 0.4952 - val_accuracy: 0.7825\n",
      "Epoch 194/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4106 - accuracy: 0.8211 - val_loss: 0.4960 - val_accuracy: 0.7869\n",
      "Epoch 195/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4107 - accuracy: 0.8230 - val_loss: 0.4940 - val_accuracy: 0.7869\n",
      "Epoch 196/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4099 - accuracy: 0.8232 - val_loss: 0.4984 - val_accuracy: 0.7810\n",
      "Epoch 197/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4110 - accuracy: 0.8209 - val_loss: 0.4946 - val_accuracy: 0.7752\n",
      "Epoch 198/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4103 - accuracy: 0.8229 - val_loss: 0.4937 - val_accuracy: 0.7839\n",
      "Epoch 199/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4108 - accuracy: 0.8225 - val_loss: 0.4971 - val_accuracy: 0.7839\n",
      "Epoch 200/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4102 - accuracy: 0.8229 - val_loss: 0.4977 - val_accuracy: 0.7883\n",
      "Epoch 201/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4111 - accuracy: 0.8217 - val_loss: 0.4935 - val_accuracy: 0.7839\n",
      "Epoch 202/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4114 - accuracy: 0.8224 - val_loss: 0.4962 - val_accuracy: 0.7869\n",
      "Epoch 203/500\n",
      "6159/6159 [==============================] - 0s 24us/step - loss: 0.4103 - accuracy: 0.8238 - val_loss: 0.4939 - val_accuracy: 0.7825\n",
      "Epoch 204/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4107 - accuracy: 0.8232 - val_loss: 0.4954 - val_accuracy: 0.7810\n",
      "Epoch 205/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4098 - accuracy: 0.8242 - val_loss: 0.4970 - val_accuracy: 0.7839\n",
      "Epoch 206/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4101 - accuracy: 0.8251 - val_loss: 0.4946 - val_accuracy: 0.7839\n",
      "Epoch 207/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4099 - accuracy: 0.8238 - val_loss: 0.4978 - val_accuracy: 0.7854\n",
      "Epoch 208/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4097 - accuracy: 0.8238 - val_loss: 0.4973 - val_accuracy: 0.7839\n",
      "Epoch 209/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4107 - accuracy: 0.8217 - val_loss: 0.4951 - val_accuracy: 0.7854\n",
      "Epoch 210/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4100 - accuracy: 0.8229 - val_loss: 0.4972 - val_accuracy: 0.7825\n",
      "Epoch 211/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4105 - accuracy: 0.8222 - val_loss: 0.4981 - val_accuracy: 0.7796\n",
      "Epoch 212/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4102 - accuracy: 0.8237 - val_loss: 0.5009 - val_accuracy: 0.7869\n",
      "Epoch 213/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4093 - accuracy: 0.8255 - val_loss: 0.4988 - val_accuracy: 0.7825\n",
      "Epoch 214/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4094 - accuracy: 0.8248 - val_loss: 0.4962 - val_accuracy: 0.7810\n",
      "Epoch 215/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4099 - accuracy: 0.8237 - val_loss: 0.4982 - val_accuracy: 0.7839\n",
      "Epoch 216/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4102 - accuracy: 0.8243 - val_loss: 0.4921 - val_accuracy: 0.7839\n",
      "Epoch 217/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4099 - accuracy: 0.8230 - val_loss: 0.4948 - val_accuracy: 0.7839\n",
      "Epoch 218/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4093 - accuracy: 0.8240 - val_loss: 0.4916 - val_accuracy: 0.7810\n",
      "Epoch 219/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4099 - accuracy: 0.8225 - val_loss: 0.4935 - val_accuracy: 0.7869\n",
      "Epoch 220/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4096 - accuracy: 0.8227 - val_loss: 0.4964 - val_accuracy: 0.7810\n",
      "Epoch 221/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4100 - accuracy: 0.8250 - val_loss: 0.4945 - val_accuracy: 0.7839\n",
      "Epoch 222/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4097 - accuracy: 0.8232 - val_loss: 0.4965 - val_accuracy: 0.7839\n",
      "Epoch 223/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4092 - accuracy: 0.8246 - val_loss: 0.4907 - val_accuracy: 0.7869\n",
      "Epoch 224/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4090 - accuracy: 0.8233 - val_loss: 0.4958 - val_accuracy: 0.7869\n",
      "Epoch 225/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4092 - accuracy: 0.8232 - val_loss: 0.4915 - val_accuracy: 0.7883\n",
      "Epoch 226/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4092 - accuracy: 0.8233 - val_loss: 0.4932 - val_accuracy: 0.7869\n",
      "Epoch 227/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4087 - accuracy: 0.8250 - val_loss: 0.4961 - val_accuracy: 0.7825\n",
      "Epoch 228/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4091 - accuracy: 0.8237 - val_loss: 0.4920 - val_accuracy: 0.7883\n",
      "Epoch 229/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4093 - accuracy: 0.8225 - val_loss: 0.4944 - val_accuracy: 0.7883\n",
      "Epoch 230/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4090 - accuracy: 0.8232 - val_loss: 0.4911 - val_accuracy: 0.7839\n",
      "Epoch 231/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4093 - accuracy: 0.8233 - val_loss: 0.4964 - val_accuracy: 0.7869\n",
      "Epoch 232/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4093 - accuracy: 0.8230 - val_loss: 0.4920 - val_accuracy: 0.7869\n",
      "Epoch 233/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4094 - accuracy: 0.8238 - val_loss: 0.4906 - val_accuracy: 0.7810\n",
      "Epoch 234/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4087 - accuracy: 0.8216 - val_loss: 0.4923 - val_accuracy: 0.7810\n",
      "Epoch 235/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4084 - accuracy: 0.8235 - val_loss: 0.4917 - val_accuracy: 0.7883\n",
      "Epoch 236/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4090 - accuracy: 0.8240 - val_loss: 0.4931 - val_accuracy: 0.7854\n",
      "Epoch 237/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4086 - accuracy: 0.8250 - val_loss: 0.4935 - val_accuracy: 0.7854\n",
      "Epoch 238/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4085 - accuracy: 0.8232 - val_loss: 0.4908 - val_accuracy: 0.7839\n",
      "Epoch 239/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4089 - accuracy: 0.8242 - val_loss: 0.4948 - val_accuracy: 0.7883\n",
      "Epoch 240/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4085 - accuracy: 0.8225 - val_loss: 0.4920 - val_accuracy: 0.7839\n",
      "Epoch 241/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4086 - accuracy: 0.8237 - val_loss: 0.4940 - val_accuracy: 0.7854\n",
      "Epoch 242/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4093 - accuracy: 0.8227 - val_loss: 0.4909 - val_accuracy: 0.7839\n",
      "Epoch 243/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4082 - accuracy: 0.8208 - val_loss: 0.4913 - val_accuracy: 0.7883\n",
      "Epoch 244/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4084 - accuracy: 0.8220 - val_loss: 0.4924 - val_accuracy: 0.7869\n",
      "Epoch 245/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4085 - accuracy: 0.8235 - val_loss: 0.4905 - val_accuracy: 0.7854\n",
      "Epoch 246/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4081 - accuracy: 0.8229 - val_loss: 0.4916 - val_accuracy: 0.7839\n",
      "Epoch 247/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4081 - accuracy: 0.8230 - val_loss: 0.4912 - val_accuracy: 0.7810\n",
      "Epoch 248/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4080 - accuracy: 0.8227 - val_loss: 0.4895 - val_accuracy: 0.7869\n",
      "Epoch 249/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4086 - accuracy: 0.8214 - val_loss: 0.4913 - val_accuracy: 0.7839\n",
      "Epoch 250/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4086 - accuracy: 0.8229 - val_loss: 0.4915 - val_accuracy: 0.7869\n",
      "Epoch 251/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4087 - accuracy: 0.8230 - val_loss: 0.4919 - val_accuracy: 0.7839\n",
      "Epoch 252/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4076 - accuracy: 0.8230 - val_loss: 0.4881 - val_accuracy: 0.7869\n",
      "Epoch 253/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4083 - accuracy: 0.8217 - val_loss: 0.4866 - val_accuracy: 0.7854\n",
      "Epoch 254/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4084 - accuracy: 0.8242 - val_loss: 0.4891 - val_accuracy: 0.7825\n",
      "Epoch 255/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4079 - accuracy: 0.8245 - val_loss: 0.4888 - val_accuracy: 0.7883\n",
      "Epoch 256/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4080 - accuracy: 0.8246 - val_loss: 0.4891 - val_accuracy: 0.7854\n",
      "Epoch 257/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4078 - accuracy: 0.8237 - val_loss: 0.4915 - val_accuracy: 0.7883\n",
      "Epoch 258/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4077 - accuracy: 0.8255 - val_loss: 0.4964 - val_accuracy: 0.7825\n",
      "Epoch 259/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4077 - accuracy: 0.8237 - val_loss: 0.4894 - val_accuracy: 0.7854\n",
      "Epoch 260/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4074 - accuracy: 0.8243 - val_loss: 0.4897 - val_accuracy: 0.7839\n",
      "Epoch 261/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4076 - accuracy: 0.8240 - val_loss: 0.4911 - val_accuracy: 0.7912\n",
      "Epoch 262/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4074 - accuracy: 0.8248 - val_loss: 0.4900 - val_accuracy: 0.7839\n",
      "Epoch 263/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4073 - accuracy: 0.8240 - val_loss: 0.4890 - val_accuracy: 0.7825\n",
      "Epoch 264/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4072 - accuracy: 0.8242 - val_loss: 0.4900 - val_accuracy: 0.7883\n",
      "Epoch 265/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4073 - accuracy: 0.8225 - val_loss: 0.4890 - val_accuracy: 0.7869\n",
      "Epoch 266/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4070 - accuracy: 0.8233 - val_loss: 0.4889 - val_accuracy: 0.7854\n",
      "Epoch 267/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4075 - accuracy: 0.8217 - val_loss: 0.4899 - val_accuracy: 0.7869\n",
      "Epoch 268/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4071 - accuracy: 0.8224 - val_loss: 0.4883 - val_accuracy: 0.7883\n",
      "Epoch 269/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4077 - accuracy: 0.8203 - val_loss: 0.4883 - val_accuracy: 0.7854\n",
      "Epoch 270/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4076 - accuracy: 0.8224 - val_loss: 0.4887 - val_accuracy: 0.7869\n",
      "Epoch 271/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4071 - accuracy: 0.8237 - val_loss: 0.4884 - val_accuracy: 0.7869\n",
      "Epoch 272/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4072 - accuracy: 0.8214 - val_loss: 0.4907 - val_accuracy: 0.7869\n",
      "Epoch 273/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4077 - accuracy: 0.8235 - val_loss: 0.4892 - val_accuracy: 0.7883\n",
      "Epoch 274/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4071 - accuracy: 0.8219 - val_loss: 0.4912 - val_accuracy: 0.7883\n",
      "Epoch 275/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4078 - accuracy: 0.8209 - val_loss: 0.4935 - val_accuracy: 0.7839\n",
      "Epoch 276/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4066 - accuracy: 0.8238 - val_loss: 0.4919 - val_accuracy: 0.7854\n",
      "Epoch 277/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4067 - accuracy: 0.8233 - val_loss: 0.4862 - val_accuracy: 0.7839\n",
      "Epoch 278/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4060 - accuracy: 0.8251 - val_loss: 0.4896 - val_accuracy: 0.7898\n",
      "Epoch 279/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4075 - accuracy: 0.8238 - val_loss: 0.4917 - val_accuracy: 0.7825\n",
      "Epoch 280/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4074 - accuracy: 0.8208 - val_loss: 0.4869 - val_accuracy: 0.7854\n",
      "Epoch 281/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4074 - accuracy: 0.8230 - val_loss: 0.4851 - val_accuracy: 0.7883\n",
      "Epoch 282/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4068 - accuracy: 0.8233 - val_loss: 0.4926 - val_accuracy: 0.7839\n",
      "Epoch 283/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4063 - accuracy: 0.8222 - val_loss: 0.4887 - val_accuracy: 0.7869\n",
      "Epoch 284/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4067 - accuracy: 0.8243 - val_loss: 0.4907 - val_accuracy: 0.7883\n",
      "Epoch 285/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4071 - accuracy: 0.8216 - val_loss: 0.4876 - val_accuracy: 0.7869\n",
      "Epoch 286/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4068 - accuracy: 0.8204 - val_loss: 0.4874 - val_accuracy: 0.7854\n",
      "Epoch 287/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4065 - accuracy: 0.8240 - val_loss: 0.4912 - val_accuracy: 0.7869\n",
      "Epoch 288/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4063 - accuracy: 0.8237 - val_loss: 0.4878 - val_accuracy: 0.7869\n",
      "Epoch 289/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.4898 - val_accuracy: 0.7839\n",
      "Epoch 290/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4057 - accuracy: 0.8238 - val_loss: 0.4879 - val_accuracy: 0.7883\n",
      "Epoch 291/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4068 - accuracy: 0.8227 - val_loss: 0.4926 - val_accuracy: 0.7869\n",
      "Epoch 292/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4066 - accuracy: 0.8233 - val_loss: 0.4889 - val_accuracy: 0.7869\n",
      "Epoch 293/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4064 - accuracy: 0.8233 - val_loss: 0.4907 - val_accuracy: 0.7839\n",
      "Epoch 294/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4061 - accuracy: 0.8232 - val_loss: 0.4881 - val_accuracy: 0.7839\n",
      "Epoch 295/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4061 - accuracy: 0.8237 - val_loss: 0.4881 - val_accuracy: 0.7898\n",
      "Epoch 296/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4059 - accuracy: 0.8217 - val_loss: 0.4870 - val_accuracy: 0.7912\n",
      "Epoch 297/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4069 - accuracy: 0.8220 - val_loss: 0.4893 - val_accuracy: 0.7839\n",
      "Epoch 298/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4063 - accuracy: 0.8240 - val_loss: 0.4885 - val_accuracy: 0.7825\n",
      "Epoch 299/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4065 - accuracy: 0.8237 - val_loss: 0.4876 - val_accuracy: 0.7854\n",
      "Epoch 300/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4062 - accuracy: 0.8227 - val_loss: 0.4913 - val_accuracy: 0.7883\n",
      "Epoch 301/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4063 - accuracy: 0.8250 - val_loss: 0.4945 - val_accuracy: 0.7869\n",
      "Epoch 302/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4065 - accuracy: 0.8214 - val_loss: 0.4878 - val_accuracy: 0.7898\n",
      "Epoch 303/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4060 - accuracy: 0.8229 - val_loss: 0.4880 - val_accuracy: 0.7839\n",
      "Epoch 304/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4062 - accuracy: 0.8201 - val_loss: 0.4903 - val_accuracy: 0.7883\n",
      "Epoch 305/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4067 - accuracy: 0.8237 - val_loss: 0.4926 - val_accuracy: 0.7869\n",
      "Epoch 306/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4062 - accuracy: 0.8227 - val_loss: 0.4895 - val_accuracy: 0.7883\n",
      "Epoch 307/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4061 - accuracy: 0.8229 - val_loss: 0.4902 - val_accuracy: 0.7839\n",
      "Epoch 308/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4062 - accuracy: 0.8230 - val_loss: 0.4884 - val_accuracy: 0.7839\n",
      "Epoch 309/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4055 - accuracy: 0.8224 - val_loss: 0.4866 - val_accuracy: 0.7839\n",
      "Epoch 310/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4059 - accuracy: 0.8227 - val_loss: 0.4862 - val_accuracy: 0.7854\n",
      "Epoch 311/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4062 - accuracy: 0.8232 - val_loss: 0.4845 - val_accuracy: 0.7869\n",
      "Epoch 312/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.4892 - val_accuracy: 0.7869\n",
      "Epoch 313/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4054 - accuracy: 0.8232 - val_loss: 0.4926 - val_accuracy: 0.7927\n",
      "Epoch 314/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4052 - accuracy: 0.8246 - val_loss: 0.4871 - val_accuracy: 0.7854\n",
      "Epoch 315/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4057 - accuracy: 0.8243 - val_loss: 0.4883 - val_accuracy: 0.7825\n",
      "Epoch 316/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4057 - accuracy: 0.8230 - val_loss: 0.4889 - val_accuracy: 0.7912\n",
      "Epoch 317/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4060 - accuracy: 0.8238 - val_loss: 0.4858 - val_accuracy: 0.7854\n",
      "Epoch 318/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4060 - accuracy: 0.8212 - val_loss: 0.4887 - val_accuracy: 0.7869\n",
      "Epoch 319/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4059 - accuracy: 0.8214 - val_loss: 0.4867 - val_accuracy: 0.7869\n",
      "Epoch 320/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4056 - accuracy: 0.8237 - val_loss: 0.4869 - val_accuracy: 0.7810\n",
      "Epoch 321/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.4870 - val_accuracy: 0.7883\n",
      "Epoch 322/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4058 - accuracy: 0.8225 - val_loss: 0.4851 - val_accuracy: 0.7869\n",
      "Epoch 323/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4056 - accuracy: 0.8237 - val_loss: 0.4863 - val_accuracy: 0.7854\n",
      "Epoch 324/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4050 - accuracy: 0.8203 - val_loss: 0.4877 - val_accuracy: 0.7912\n",
      "Epoch 325/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4069 - accuracy: 0.8232 - val_loss: 0.4899 - val_accuracy: 0.7854\n",
      "Epoch 326/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4055 - accuracy: 0.8219 - val_loss: 0.4873 - val_accuracy: 0.7898\n",
      "Epoch 327/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4055 - accuracy: 0.8227 - val_loss: 0.4872 - val_accuracy: 0.7898\n",
      "Epoch 328/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4056 - accuracy: 0.8230 - val_loss: 0.4926 - val_accuracy: 0.7869\n",
      "Epoch 329/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4057 - accuracy: 0.8255 - val_loss: 0.4867 - val_accuracy: 0.7854\n",
      "Epoch 330/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4058 - accuracy: 0.8222 - val_loss: 0.4865 - val_accuracy: 0.7869\n",
      "Epoch 331/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4052 - accuracy: 0.8224 - val_loss: 0.4853 - val_accuracy: 0.7781\n",
      "Epoch 332/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4060 - accuracy: 0.8209 - val_loss: 0.4897 - val_accuracy: 0.7869\n",
      "Epoch 333/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4054 - accuracy: 0.8222 - val_loss: 0.4861 - val_accuracy: 0.7825\n",
      "Epoch 334/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4052 - accuracy: 0.8235 - val_loss: 0.4896 - val_accuracy: 0.7883\n",
      "Epoch 335/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4044 - accuracy: 0.8237 - val_loss: 0.4864 - val_accuracy: 0.7883\n",
      "Epoch 336/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4059 - accuracy: 0.8230 - val_loss: 0.4893 - val_accuracy: 0.7898\n",
      "Epoch 337/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4052 - accuracy: 0.8227 - val_loss: 0.4854 - val_accuracy: 0.7898\n",
      "Epoch 338/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4054 - accuracy: 0.8229 - val_loss: 0.4862 - val_accuracy: 0.7898\n",
      "Epoch 339/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4050 - accuracy: 0.8227 - val_loss: 0.4911 - val_accuracy: 0.7854\n",
      "Epoch 340/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4048 - accuracy: 0.8233 - val_loss: 0.4881 - val_accuracy: 0.7854\n",
      "Epoch 341/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4039 - accuracy: 0.8225 - val_loss: 0.4855 - val_accuracy: 0.7854\n",
      "Epoch 342/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4062 - accuracy: 0.8230 - val_loss: 0.4858 - val_accuracy: 0.7825\n",
      "Epoch 343/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4052 - accuracy: 0.8220 - val_loss: 0.4862 - val_accuracy: 0.7898\n",
      "Epoch 344/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4040 - accuracy: 0.8233 - val_loss: 0.4870 - val_accuracy: 0.7854\n",
      "Epoch 345/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4044 - accuracy: 0.8219 - val_loss: 0.4849 - val_accuracy: 0.7854\n",
      "Epoch 346/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4047 - accuracy: 0.8225 - val_loss: 0.4862 - val_accuracy: 0.7898\n",
      "Epoch 347/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4050 - accuracy: 0.8232 - val_loss: 0.4857 - val_accuracy: 0.7825\n",
      "Epoch 348/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4043 - accuracy: 0.8214 - val_loss: 0.4872 - val_accuracy: 0.7869\n",
      "Epoch 349/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4047 - accuracy: 0.8227 - val_loss: 0.4868 - val_accuracy: 0.7810\n",
      "Epoch 350/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4043 - accuracy: 0.8222 - val_loss: 0.4911 - val_accuracy: 0.7839\n",
      "Epoch 351/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4049 - accuracy: 0.8217 - val_loss: 0.4882 - val_accuracy: 0.7825\n",
      "Epoch 352/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4038 - accuracy: 0.8232 - val_loss: 0.4874 - val_accuracy: 0.7883\n",
      "Epoch 353/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4041 - accuracy: 0.8219 - val_loss: 0.4888 - val_accuracy: 0.7825\n",
      "Epoch 354/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4044 - accuracy: 0.8225 - val_loss: 0.4898 - val_accuracy: 0.7898\n",
      "Epoch 355/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4040 - accuracy: 0.8246 - val_loss: 0.4888 - val_accuracy: 0.7781\n",
      "Epoch 356/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4043 - accuracy: 0.8220 - val_loss: 0.4878 - val_accuracy: 0.7883\n",
      "Epoch 357/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4038 - accuracy: 0.8201 - val_loss: 0.4899 - val_accuracy: 0.7854\n",
      "Epoch 358/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4037 - accuracy: 0.8230 - val_loss: 0.4908 - val_accuracy: 0.7898\n",
      "Epoch 359/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4036 - accuracy: 0.8222 - val_loss: 0.4873 - val_accuracy: 0.7839\n",
      "Epoch 360/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4034 - accuracy: 0.8224 - val_loss: 0.4883 - val_accuracy: 0.7839\n",
      "Epoch 361/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4039 - accuracy: 0.8216 - val_loss: 0.4879 - val_accuracy: 0.7766\n",
      "Epoch 362/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4029 - accuracy: 0.8222 - val_loss: 0.4891 - val_accuracy: 0.7854\n",
      "Epoch 363/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4047 - accuracy: 0.8217 - val_loss: 0.4865 - val_accuracy: 0.7869\n",
      "Epoch 364/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4039 - accuracy: 0.8219 - val_loss: 0.4871 - val_accuracy: 0.7839\n",
      "Epoch 365/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4043 - accuracy: 0.8225 - val_loss: 0.4915 - val_accuracy: 0.7825\n",
      "Epoch 366/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4041 - accuracy: 0.8225 - val_loss: 0.4913 - val_accuracy: 0.7854\n",
      "Epoch 367/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4039 - accuracy: 0.8216 - val_loss: 0.4899 - val_accuracy: 0.7869\n",
      "Epoch 368/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.4891 - val_accuracy: 0.7869\n",
      "Epoch 369/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4030 - accuracy: 0.8232 - val_loss: 0.4910 - val_accuracy: 0.7839\n",
      "Epoch 370/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4030 - accuracy: 0.8238 - val_loss: 0.4885 - val_accuracy: 0.7869\n",
      "Epoch 371/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4029 - accuracy: 0.8224 - val_loss: 0.4896 - val_accuracy: 0.7825\n",
      "Epoch 372/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4034 - accuracy: 0.8222 - val_loss: 0.4888 - val_accuracy: 0.7854\n",
      "Epoch 373/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4030 - accuracy: 0.8222 - val_loss: 0.4870 - val_accuracy: 0.7854\n",
      "Epoch 374/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4032 - accuracy: 0.8191 - val_loss: 0.4914 - val_accuracy: 0.7854\n",
      "Epoch 375/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4035 - accuracy: 0.8248 - val_loss: 0.4903 - val_accuracy: 0.7883\n",
      "Epoch 376/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4031 - accuracy: 0.8217 - val_loss: 0.4901 - val_accuracy: 0.7839\n",
      "Epoch 377/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4026 - accuracy: 0.8222 - val_loss: 0.4898 - val_accuracy: 0.7810\n",
      "Epoch 378/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4031 - accuracy: 0.8238 - val_loss: 0.4909 - val_accuracy: 0.7883\n",
      "Epoch 379/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4028 - accuracy: 0.8240 - val_loss: 0.4907 - val_accuracy: 0.7854\n",
      "Epoch 380/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4037 - accuracy: 0.8253 - val_loss: 0.4977 - val_accuracy: 0.7898\n",
      "Epoch 381/500\n",
      "6159/6159 [==============================] - 0s 23us/step - loss: 0.4030 - accuracy: 0.8212 - val_loss: 0.4868 - val_accuracy: 0.7810\n",
      "Epoch 382/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4026 - accuracy: 0.8220 - val_loss: 0.4884 - val_accuracy: 0.7825\n",
      "Epoch 383/500\n",
      "6159/6159 [==============================] - 0s 21us/step - loss: 0.4031 - accuracy: 0.8220 - val_loss: 0.4889 - val_accuracy: 0.7898\n",
      "Epoch 384/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4027 - accuracy: 0.8240 - val_loss: 0.4902 - val_accuracy: 0.7854\n",
      "Epoch 385/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4031 - accuracy: 0.8245 - val_loss: 0.4897 - val_accuracy: 0.7766\n",
      "Epoch 386/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4029 - accuracy: 0.8227 - val_loss: 0.4890 - val_accuracy: 0.7898\n",
      "Epoch 387/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4030 - accuracy: 0.8225 - val_loss: 0.4897 - val_accuracy: 0.7869\n",
      "Epoch 388/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4029 - accuracy: 0.8225 - val_loss: 0.4874 - val_accuracy: 0.7810\n",
      "Epoch 389/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4027 - accuracy: 0.8230 - val_loss: 0.4898 - val_accuracy: 0.7825\n",
      "Epoch 390/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4029 - accuracy: 0.8243 - val_loss: 0.4884 - val_accuracy: 0.7854\n",
      "Epoch 391/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4032 - accuracy: 0.8232 - val_loss: 0.4885 - val_accuracy: 0.7796\n",
      "Epoch 392/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4031 - accuracy: 0.8216 - val_loss: 0.4872 - val_accuracy: 0.7898\n",
      "Epoch 393/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4033 - accuracy: 0.8224 - val_loss: 0.4909 - val_accuracy: 0.7839\n",
      "Epoch 394/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4031 - accuracy: 0.8233 - val_loss: 0.4895 - val_accuracy: 0.7883\n",
      "Epoch 395/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4028 - accuracy: 0.8230 - val_loss: 0.4891 - val_accuracy: 0.7869\n",
      "Epoch 396/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4022 - accuracy: 0.8227 - val_loss: 0.4877 - val_accuracy: 0.7825\n",
      "Epoch 397/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4027 - accuracy: 0.8251 - val_loss: 0.4884 - val_accuracy: 0.7869\n",
      "Epoch 398/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4028 - accuracy: 0.8227 - val_loss: 0.4894 - val_accuracy: 0.7810\n",
      "Epoch 399/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4026 - accuracy: 0.8217 - val_loss: 0.4898 - val_accuracy: 0.7839\n",
      "Epoch 400/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4019 - accuracy: 0.8217 - val_loss: 0.4985 - val_accuracy: 0.7927\n",
      "Epoch 401/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4040 - accuracy: 0.8229 - val_loss: 0.4943 - val_accuracy: 0.7912\n",
      "Epoch 402/500\n",
      "6159/6159 [==============================] - 0s 24us/step - loss: 0.4032 - accuracy: 0.8232 - val_loss: 0.4882 - val_accuracy: 0.7854\n",
      "Epoch 403/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4019 - accuracy: 0.8263 - val_loss: 0.4884 - val_accuracy: 0.7796\n",
      "Epoch 404/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4025 - accuracy: 0.8235 - val_loss: 0.4929 - val_accuracy: 0.7927\n",
      "Epoch 405/500\n",
      "6159/6159 [==============================] - 0s 23us/step - loss: 0.4022 - accuracy: 0.8230 - val_loss: 0.4886 - val_accuracy: 0.7810\n",
      "Epoch 406/500\n",
      "6159/6159 [==============================] - 0s 23us/step - loss: 0.4022 - accuracy: 0.8233 - val_loss: 0.4899 - val_accuracy: 0.7869\n",
      "Epoch 407/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4022 - accuracy: 0.8243 - val_loss: 0.4884 - val_accuracy: 0.7869\n",
      "Epoch 408/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4024 - accuracy: 0.8237 - val_loss: 0.4866 - val_accuracy: 0.7796\n",
      "Epoch 409/500\n",
      "6159/6159 [==============================] - 0s 31us/step - loss: 0.4027 - accuracy: 0.8253 - val_loss: 0.4907 - val_accuracy: 0.7839\n",
      "Epoch 410/500\n",
      "6159/6159 [==============================] - 0s 42us/step - loss: 0.4022 - accuracy: 0.8211 - val_loss: 0.4873 - val_accuracy: 0.7869\n",
      "Epoch 411/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4023 - accuracy: 0.8251 - val_loss: 0.4875 - val_accuracy: 0.7796\n",
      "Epoch 412/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4022 - accuracy: 0.8233 - val_loss: 0.4860 - val_accuracy: 0.7810\n",
      "Epoch 413/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4017 - accuracy: 0.8229 - val_loss: 0.4903 - val_accuracy: 0.7912\n",
      "Epoch 414/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4018 - accuracy: 0.8251 - val_loss: 0.4957 - val_accuracy: 0.7898\n",
      "Epoch 415/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4030 - accuracy: 0.8220 - val_loss: 0.4868 - val_accuracy: 0.7869\n",
      "Epoch 416/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4034 - accuracy: 0.8222 - val_loss: 0.4925 - val_accuracy: 0.7912\n",
      "Epoch 417/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4022 - accuracy: 0.8212 - val_loss: 0.4853 - val_accuracy: 0.7854\n",
      "Epoch 418/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4022 - accuracy: 0.8243 - val_loss: 0.4857 - val_accuracy: 0.7854\n",
      "Epoch 419/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4029 - accuracy: 0.8250 - val_loss: 0.4895 - val_accuracy: 0.7869\n",
      "Epoch 420/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4022 - accuracy: 0.8233 - val_loss: 0.4882 - val_accuracy: 0.7825\n",
      "Epoch 421/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4028 - accuracy: 0.8227 - val_loss: 0.4879 - val_accuracy: 0.7869\n",
      "Epoch 422/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4022 - accuracy: 0.8248 - val_loss: 0.4889 - val_accuracy: 0.7869\n",
      "Epoch 423/500\n",
      "6159/6159 [==============================] - 0s 22us/step - loss: 0.4020 - accuracy: 0.8235 - val_loss: 0.4895 - val_accuracy: 0.7825\n",
      "Epoch 424/500\n",
      "6159/6159 [==============================] - 0s 24us/step - loss: 0.4021 - accuracy: 0.8256 - val_loss: 0.4885 - val_accuracy: 0.7839\n",
      "Epoch 425/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4020 - accuracy: 0.8235 - val_loss: 0.4890 - val_accuracy: 0.7869\n",
      "Epoch 426/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4019 - accuracy: 0.8240 - val_loss: 0.4927 - val_accuracy: 0.7839\n",
      "Epoch 427/500\n",
      "6159/6159 [==============================] - 0s 21us/step - loss: 0.4017 - accuracy: 0.8256 - val_loss: 0.4915 - val_accuracy: 0.7942\n",
      "Epoch 428/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4018 - accuracy: 0.8220 - val_loss: 0.4881 - val_accuracy: 0.7839\n",
      "Epoch 429/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4026 - accuracy: 0.8256 - val_loss: 0.4896 - val_accuracy: 0.7883\n",
      "Epoch 430/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4017 - accuracy: 0.8250 - val_loss: 0.4930 - val_accuracy: 0.7927\n",
      "Epoch 431/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4020 - accuracy: 0.8248 - val_loss: 0.4889 - val_accuracy: 0.7854\n",
      "Epoch 432/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4020 - accuracy: 0.8258 - val_loss: 0.4900 - val_accuracy: 0.7825\n",
      "Epoch 433/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4025 - accuracy: 0.8245 - val_loss: 0.4871 - val_accuracy: 0.7883\n",
      "Epoch 434/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4024 - accuracy: 0.8229 - val_loss: 0.4897 - val_accuracy: 0.7810\n",
      "Epoch 435/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4017 - accuracy: 0.8242 - val_loss: 0.4910 - val_accuracy: 0.7883\n",
      "Epoch 436/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4018 - accuracy: 0.8233 - val_loss: 0.4887 - val_accuracy: 0.7825\n",
      "Epoch 437/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4017 - accuracy: 0.8245 - val_loss: 0.4898 - val_accuracy: 0.7839\n",
      "Epoch 438/500\n",
      "6159/6159 [==============================] - 0s 13us/step - loss: 0.4017 - accuracy: 0.8227 - val_loss: 0.4883 - val_accuracy: 0.7839\n",
      "Epoch 439/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4029 - accuracy: 0.8250 - val_loss: 0.4873 - val_accuracy: 0.7898\n",
      "Epoch 440/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4019 - accuracy: 0.8250 - val_loss: 0.4888 - val_accuracy: 0.7825\n",
      "Epoch 441/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4021 - accuracy: 0.8255 - val_loss: 0.4869 - val_accuracy: 0.7869\n",
      "Epoch 442/500\n",
      "6159/6159 [==============================] - 0s 14us/step - loss: 0.4011 - accuracy: 0.8248 - val_loss: 0.4904 - val_accuracy: 0.7869\n",
      "Epoch 443/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4020 - accuracy: 0.8238 - val_loss: 0.4896 - val_accuracy: 0.7796\n",
      "Epoch 444/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4023 - accuracy: 0.8237 - val_loss: 0.4894 - val_accuracy: 0.7839\n",
      "Epoch 445/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4014 - accuracy: 0.8235 - val_loss: 0.4906 - val_accuracy: 0.7883\n",
      "Epoch 446/500\n",
      "6159/6159 [==============================] - 0s 21us/step - loss: 0.4016 - accuracy: 0.8246 - val_loss: 0.4887 - val_accuracy: 0.7898\n",
      "Epoch 447/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4023 - accuracy: 0.8259 - val_loss: 0.4929 - val_accuracy: 0.7927\n",
      "Epoch 448/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4019 - accuracy: 0.8243 - val_loss: 0.4895 - val_accuracy: 0.7869\n",
      "Epoch 449/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4013 - accuracy: 0.8225 - val_loss: 0.4943 - val_accuracy: 0.7912\n",
      "Epoch 450/500\n",
      "6159/6159 [==============================] - 0s 14us/step - loss: 0.4015 - accuracy: 0.8230 - val_loss: 0.4894 - val_accuracy: 0.7810\n",
      "Epoch 451/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4017 - accuracy: 0.8263 - val_loss: 0.4898 - val_accuracy: 0.7869\n",
      "Epoch 452/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4017 - accuracy: 0.8264 - val_loss: 0.4912 - val_accuracy: 0.7854\n",
      "Epoch 453/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4020 - accuracy: 0.8235 - val_loss: 0.4885 - val_accuracy: 0.7869\n",
      "Epoch 454/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4015 - accuracy: 0.8251 - val_loss: 0.4899 - val_accuracy: 0.7898\n",
      "Epoch 455/500\n",
      "6159/6159 [==============================] - 0s 13us/step - loss: 0.4014 - accuracy: 0.8256 - val_loss: 0.4924 - val_accuracy: 0.7883\n",
      "Epoch 456/500\n",
      "6159/6159 [==============================] - 0s 13us/step - loss: 0.4016 - accuracy: 0.8212 - val_loss: 0.4906 - val_accuracy: 0.7869\n",
      "Epoch 457/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4022 - accuracy: 0.8276 - val_loss: 0.4924 - val_accuracy: 0.7942\n",
      "Epoch 458/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4006 - accuracy: 0.8242 - val_loss: 0.4881 - val_accuracy: 0.7898\n",
      "Epoch 459/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4018 - accuracy: 0.8235 - val_loss: 0.4904 - val_accuracy: 0.7898\n",
      "Epoch 460/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4018 - accuracy: 0.8261 - val_loss: 0.4904 - val_accuracy: 0.7942\n",
      "Epoch 461/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4022 - accuracy: 0.8272 - val_loss: 0.4910 - val_accuracy: 0.7912\n",
      "Epoch 462/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4015 - accuracy: 0.8237 - val_loss: 0.4893 - val_accuracy: 0.7869\n",
      "Epoch 463/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4015 - accuracy: 0.8251 - val_loss: 0.4906 - val_accuracy: 0.7883\n",
      "Epoch 464/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4017 - accuracy: 0.8233 - val_loss: 0.4874 - val_accuracy: 0.7839\n",
      "Epoch 465/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4022 - accuracy: 0.8276 - val_loss: 0.4945 - val_accuracy: 0.7942\n",
      "Epoch 466/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4016 - accuracy: 0.8256 - val_loss: 0.4908 - val_accuracy: 0.7912\n",
      "Epoch 467/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4018 - accuracy: 0.8227 - val_loss: 0.4911 - val_accuracy: 0.7883\n",
      "Epoch 468/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4010 - accuracy: 0.8272 - val_loss: 0.4887 - val_accuracy: 0.7927\n",
      "Epoch 469/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4007 - accuracy: 0.8261 - val_loss: 0.4961 - val_accuracy: 0.7898\n",
      "Epoch 470/500\n",
      "6159/6159 [==============================] - 0s 18us/step - loss: 0.4016 - accuracy: 0.8235 - val_loss: 0.4914 - val_accuracy: 0.7898\n",
      "Epoch 471/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4016 - accuracy: 0.8266 - val_loss: 0.4963 - val_accuracy: 0.7942\n",
      "Epoch 472/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4013 - accuracy: 0.8242 - val_loss: 0.4885 - val_accuracy: 0.7898\n",
      "Epoch 473/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4017 - accuracy: 0.8253 - val_loss: 0.4936 - val_accuracy: 0.7883\n",
      "Epoch 474/500\n",
      "6159/6159 [==============================] - 0s 14us/step - loss: 0.4012 - accuracy: 0.8242 - val_loss: 0.4897 - val_accuracy: 0.7869\n",
      "Epoch 475/500\n",
      "6159/6159 [==============================] - 0s 14us/step - loss: 0.4012 - accuracy: 0.8256 - val_loss: 0.4935 - val_accuracy: 0.7912\n",
      "Epoch 476/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4012 - accuracy: 0.8238 - val_loss: 0.4906 - val_accuracy: 0.7927\n",
      "Epoch 477/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4015 - accuracy: 0.8243 - val_loss: 0.4886 - val_accuracy: 0.7942\n",
      "Epoch 478/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4009 - accuracy: 0.8246 - val_loss: 0.4883 - val_accuracy: 0.7927\n",
      "Epoch 479/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4014 - accuracy: 0.8264 - val_loss: 0.4891 - val_accuracy: 0.7883\n",
      "Epoch 480/500\n",
      "6159/6159 [==============================] - 0s 24us/step - loss: 0.4009 - accuracy: 0.8258 - val_loss: 0.4885 - val_accuracy: 0.7898\n",
      "Epoch 481/500\n",
      "6159/6159 [==============================] - 0s 22us/step - loss: 0.4012 - accuracy: 0.8229 - val_loss: 0.4919 - val_accuracy: 0.7883\n",
      "Epoch 482/500\n",
      "6159/6159 [==============================] - 0s 25us/step - loss: 0.4008 - accuracy: 0.8245 - val_loss: 0.4899 - val_accuracy: 0.7898\n",
      "Epoch 483/500\n",
      "6159/6159 [==============================] - 0s 31us/step - loss: 0.4011 - accuracy: 0.8268 - val_loss: 0.4907 - val_accuracy: 0.7898\n",
      "Epoch 484/500\n",
      "6159/6159 [==============================] - 0s 24us/step - loss: 0.4015 - accuracy: 0.8245 - val_loss: 0.4894 - val_accuracy: 0.7912\n",
      "Epoch 485/500\n",
      "6159/6159 [==============================] - 0s 27us/step - loss: 0.4017 - accuracy: 0.8256 - val_loss: 0.4909 - val_accuracy: 0.7883\n",
      "Epoch 486/500\n",
      "6159/6159 [==============================] - 0s 21us/step - loss: 0.4009 - accuracy: 0.8235 - val_loss: 0.4920 - val_accuracy: 0.7927\n",
      "Epoch 487/500\n",
      "6159/6159 [==============================] - 0s 27us/step - loss: 0.4002 - accuracy: 0.8276 - val_loss: 0.4896 - val_accuracy: 0.7883\n",
      "Epoch 488/500\n",
      "6159/6159 [==============================] - 0s 26us/step - loss: 0.4003 - accuracy: 0.8264 - val_loss: 0.4970 - val_accuracy: 0.7956\n",
      "Epoch 489/500\n",
      "6159/6159 [==============================] - 0s 26us/step - loss: 0.4013 - accuracy: 0.8230 - val_loss: 0.4919 - val_accuracy: 0.7912\n",
      "Epoch 490/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4012 - accuracy: 0.8266 - val_loss: 0.4898 - val_accuracy: 0.7883\n",
      "Epoch 491/500\n",
      "6159/6159 [==============================] - 0s 16us/step - loss: 0.4006 - accuracy: 0.8255 - val_loss: 0.4921 - val_accuracy: 0.7956\n",
      "Epoch 492/500\n",
      "6159/6159 [==============================] - 0s 13us/step - loss: 0.4009 - accuracy: 0.8272 - val_loss: 0.4930 - val_accuracy: 0.7898\n",
      "Epoch 493/500\n",
      "6159/6159 [==============================] - 0s 19us/step - loss: 0.4011 - accuracy: 0.8256 - val_loss: 0.4892 - val_accuracy: 0.7883\n",
      "Epoch 494/500\n",
      "6159/6159 [==============================] - 0s 13us/step - loss: 0.4009 - accuracy: 0.8266 - val_loss: 0.4903 - val_accuracy: 0.7956\n",
      "Epoch 495/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4007 - accuracy: 0.8264 - val_loss: 0.4894 - val_accuracy: 0.7883\n",
      "Epoch 496/500\n",
      "6159/6159 [==============================] - 0s 17us/step - loss: 0.4016 - accuracy: 0.8259 - val_loss: 0.4919 - val_accuracy: 0.7942\n",
      "Epoch 497/500\n",
      "6159/6159 [==============================] - 0s 15us/step - loss: 0.4018 - accuracy: 0.8268 - val_loss: 0.4911 - val_accuracy: 0.7971\n",
      "Epoch 498/500\n",
      "6159/6159 [==============================] - 0s 20us/step - loss: 0.4010 - accuracy: 0.8264 - val_loss: 0.4891 - val_accuracy: 0.7912\n",
      "Epoch 499/500\n",
      "6159/6159 [==============================] - 0s 27us/step - loss: 0.4005 - accuracy: 0.8271 - val_loss: 0.4897 - val_accuracy: 0.7927\n",
      "Epoch 500/500\n",
      "6159/6159 [==============================] - 0s 27us/step - loss: 0.4010 - accuracy: 0.8269 - val_loss: 0.4912 - val_accuracy: 0.7927\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=500, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5gV1dnAf+/2vktZ2tKRKgooghVBNGKLMfYYeyyJxpZiSYzYol+MJjEaa9RYYi/BiogFFFRAeu+wdFjYXm453x9n5t65c+eWXfZS9PyeZ5+9M3Nm5kw773nLeY8opTAYDAaDwU3a3q6AwWAwGPZNjIAwGAwGgydGQBgMBoPBEyMgDAaDweCJERAGg8Fg8MQICIPBYDB4YgSEwdDKiMh4EXkxybKfi8gvUl0ng6ElGAFh2CNYDeFOEcl2rX9ORJSIjHCsO0BElGvfBhHp5lh3vIis2SOV38uIyCXWPTpnb9fF8MPCCAhDyhGRnsAxgAJ+7FGkArgnwWFqgdtbtWL7Dxej79HFe/KkIpKxJ89n2PcwAsKwJ7gI+Bp4Du9G7j/AwSJybJxjPAycLyIHtEaFLK3kHhGZJiI1IvKuiLQTkZdEpEpEZliCzS5/pLWu0vp/pGNbLxH5QkSqRWQS0N51rsOt8+wSkbkiMroZ9ewBHAtcCZwoIh0d29JF5DYRWWmde5atZYnIgSIySUQqRGSLiNxmrX9ORO5xHGO0iJQ7lteIyM0iMg+oFZEMEbnFcY5FInKGq45XiMhix/ZDROR3IvKmq9w/ReTvyV67Ye9jBIRhT3AR8JL1F9HIWdQBfwbujXOMDcBTwPhWrNd5wIVAGdAHmA48C7QFFgN3AIhIW+B9tJBqBzwEvC8i7azj/BeYhRYMd+MQgiJSZu17j3Xc3wJvikhpknW8CJiplHrTqtMFjm03AecDJwNFwGVAnYgUAp8AHwFdgAOAyUmeD+uYpwAlSik/sBKtARYDdwIvikhn6/rORj+Ti6w6/BjYAbwIjBOREqtcBnAu8EIz6mHYyxgBYUgpInI00AN4TSk1C93Y/Myj6BNAdxE5Kc7h7gNOE5EDW6l6zyqlViqlKoEPgZVKqU+sRvF1YJhV7hRguVLqBaWUXyn1MrDEqkt34DDgdqVUo1JqCvCu4xw/Bz5QSn2glAoqpSYBM9GNejJchBZAWP+dGtgvgD8qpZYqzVyl1A7gVGCzUupBpVSDUqpaKfVNM+7Lw0qp9UqpegCl1OtKqY1W/V8FlgO2z+gXwF+UUjOsOqxQSq1VSm0CpgBnW+XGAdutd8Cwn2AEhCHVXAx8rJTabi27GzkAlFKN6N733YB4HUgptQ14BLgr3gkts0uN9fd4nKJbHL/rPZYLrN9dgLWufdeiNY8uwE6lVK1rm00P4GzLvLRLRHYBRwOd412DdR1HAb2AV6xV/wUOEpGh1nI3tMB1E2t9sqx31eMiEZnjqP9gwma0eOf6D1pAYv032sN+hhEQhpQhIrnAOcCxIrJZRDYDNwJDRGSIxy7Pos0YZ3hss3kAGAMcGquAUurPSqkC6+/qll9BiI3oht5Jd7TZaxPQRkTyXdts1gMvKKVKHH/5Sqn7kzjvxWhhOce6d7YWcJHj2H089ou1HrSzP8+x3MmjjDOCrAfatHct0E4pVQIsICzE453rHbRvaTBaq3kpRjnDPooREIZU8hMgAAwChlp/A4GphBu5EJZpZzxwc6wDKqV2AQ8Cv2/96sbkA6CfiPzMctqei76m95RSa9EmoztFJMsyqZ3m2PdFtCnqRMupnGM5hrvGO6GI5KCF65WE791Q4NfABZZN/2ngbhHpK5qDLb/Ie0AnEblBRLJFpFBERlqHngOcLCJtRaQTcEOCa89HC4xtVr0uRWsQNk8DvxWRQ606HGAJFZRSDcAbaM3nW6XUugTnMuxjGAFhSCUXo+3865RSm+0/tJnIbuTcvIzulcfjH2jBs0dw2PV/g3bA/h441WE2+xkwEh2KegfwvGPf9cDpwG3oRnY98DsSf3s/QZu5nnfdu38D6Wib/kPAa8DHQJW1LVcpVQ2cgBZUm9E+gzHWcV8A5gJrrP1eTXDti9ACeTraBHcQ8JVj++vo4IL/AtVoraGt4xD/sfYx5qX9EDETBhkMhlRhOfGXAJ2UUlV7uz6G5mE0CIPBkBJEJA0divuKEQ77J2akpMFgaHUsp/0WdETXuL1cHUMLSakGISLjRGSpiKwQkVs8theLHsE6V0QWWg4wLEfet471d6ayngaDoXVRStVaUWQHWn4Yw35IynwQIpIOLEM7y8qBGcD5ltPLLnMbUKyUutkaWboUHXbnA/KVUjUikgl8CVyvlPo6JZU1GAwGQxSpNDGNAFYopVYBiMgr6GiORY4yCigUEUEPSqoA/EpLrRqrTKb1l1CStW/fXvXs2bPVLsBgMBi+78yaNWu7Usoz9UsqBUQZkSMyy9GhgE4eASagByIVAucqpYIQ0kBmofPIPBorVYCIXImOFad79+7MnDmzNa/BYDAYvteIiDtLQIhU+iC80iW4tYAT0QN3uqAHAT0iIkUASqmAUmoo0BUYYY3GjD6gUk8qpYYrpYaXliab/8xgMBgMiUilgChH52mx6YrWFJxcCrxlJ/kCVgMDnAWskbOfYyIhDAaDYY+SSgExA+grOld+Fjq18gRXmXXAWAArBXR/YJWIlDrSBOcCx6MH2xgMBoNhD5EyH4RSyi8i1wIT0akBnlFKLRSRq63tj6Mzdz4nIvPRJqmblVLbReRg4D+WHyINnSr6vZbUw+fzUV5eTkNDQ2tc1veWnJwcunbtSmZm5t6uisFg2Ef4XqXaGD58uHI7qVevXk1hYSHt2rVDB0sZ3Cil2LFjB9XV1fTq1WtvV8dgMOxBRGSWUmq417bvfaqNhoYGIxwSICK0a9fOaFkGgyGC772AAIxwSAJzjwwGg5sfhIAwGAyGPc2MNRUs2RyZo/CzpVtZX1HXrONs3FXPJ4u2JC6YAoyASCE7duxg6NChDB06lE6dOlFWVhZabmpqirvvzJkzue666xKe48gjj2yt6hoMhlbk7MenM+7vU/EHgizaqAXFpc/O4PiHvmDRxir8gWBSx7nomW/5xfMzafAFaPAFWLG1OpXVjsAIiBTSrl075syZw5w5c7j66qu58cYbQ8tZWVn4/f6Y+w4fPpyHH3444TmmTZvWmlU2GAytzL0fLObkh6eGNIdGf5CTH57KPe8vTmr/bdWNAKyrqOM3r83l+IemUN+k58uqafTzp/8tYNmW1AgNIyD2MJdccgk33XQTY8aM4eabb+bbb7/lyCOPZNiwYRx55JEsXboUgM8//5xTTz0VgPHjx3PZZZcxevRoevfuHSE4CgoKQuVHjx7NWWedxYABA7jggguwI9Q++OADBgwYwNFHH811110XOq7BYEg9ExdsBqCiNtJq8OGC+BMnTly4mfUVdXQqygFg9fZaPl+6FYCt1Q1sq27kyudn8vz0tfzob1OoaYzd4WwpP6j5IO58d2FI1WstBnUp4o7TDmzWPsuWLeOTTz4hPT2dqqoqpkyZQkZGBp988gm33XYbb775ZtQ+S5Ys4bPPPqO6upr+/fvzy1/+MmrMwuzZs1m4cCFdunThqKOO4quvvmL48OFcddVVTJkyhV69enH++efv1vUaDIbYLNtSTZu8LEoLs0PrtloagFtAbKlqZPAdE/nohmPo2iYPgEZ/gOVbajiwSxFXvTCLtvlZDC4rZumWan710ncEgrrTd+wDn9OlOIeNlTry8OHzh1GQ3frNudEg9gJnn3026enpAFRWVnL22WczePBgbrzxRhYuXOi5zymnnEJ2djbt27enQ4cObNkS7bQaMWIEXbt2JS0tjaFDh7JmzRqWLFlC7969Q+MbjIAw/BB4Y1Y5b88u36PnnLmmgh/9bQp3vhv5DfutRn1HbbTfsabRz4fzN4eWH568nFP/+SUz1+4EtFDJSNMRhrZwsLGFw7H9SvnxkC6tdyEOflAaRHN7+qkiPz8/9Pv2229nzJgxvP3226xZs4bRo0d77pOdHe6RpKene/ovvMp8nwZCGgzJ8tvX5wJwxrCuKT/XxIWb6VNawBfLtgFhjcHNjhrv9QHHN7pmh/ZTTHJELdn+Bi9K8jJ54sJDm13nZDEaxF6msrKSsrIyAJ577rlWP/6AAQNYtWoVa9asAeDVV19t9XMYDN8Hlm6uprLOx+x1O1m0sYoNu+o54r7JTF4cO8Q0GFRc9/Jsnp66KuQDEGB+eWVUWS8NArRmsHp7LVurGyi0zEROAbF8a43nfgM7F/GXMw8mJzM92UtsNj8oDWJf5Pe//z0XX3wxDz30EMcdd1yrHz83N5d//etfjBs3jvbt2zNixIhWP8f3gY8WbGLV9lp+NfqAlJ+rttHP7e8s4JaTB9ChMCfl59tdHv1sBYO6FDGmf4c9fu4GX4A0EbIydq8vW93goyA7I+6A0BP/PoU0AZclh3s/WMzYgR1Dy5MXb2Hm2p3cPG4AW6obaPQH2VLVEPI7LNxYxWmPfBl1/O0xNIjKeh9j/vo5WRlpjOrbHtAO6Xj7jejVlteuOiL2BbcS3/tcTIsXL2bgwIF7qUb7BjU1NRQUFKCU4pprrqFv377ceOONUeV+SPfq/Xmb6NuxgH4dCwHoecv7ACy5e1xKe2QAL3+7jlvfms/PD+/OPT85KKl93phVzshebenWNi+ldfPCvjdr7j9lr5y7V/t8Pvvt6Ljlttc0MnHhZi4Y2SO0H+g6b6lqYOSfJzOyV1vuOO1A5m/Yxej+HehYFBbO9U0BBv7pI89jDy4r4r1fHxNRJ4BZfzye5VtrOO/JrzmwSxE92+Xz/vz4kUmJGNK1mLke2oeT9687mn4dC8lMbx0D0A86F9O+yIqtNWyp2nN5j5566imGDh3KgQceSGVlJVddddUeO3cq+HTJFnre8j6V9b4W7e8PBLnmv99x0j+mRm2bZTkHAa56YSbXvTwbgKoGHwNv/4jPlmyNKB8IKobfM4k3ZiXvELWdjYGgYu2O2oQja+ubAvz29bmc+8T0pM9hM/yeSTzz5epm72fjdozuCVZui/w+nL3pWFz/ymz+8PYCVm+vjaizPxBkhWWi+WZ1BSc/PJWb35zPlS/Mwh8IcsR9k3l7dnnckNM0h9Zx/SuzQ7+/XlXBOstnsLW6sVXCTLfF8F/YXDWqNwd2KW414ZAIIyBSgD8YZN2OWnzWSMmgUviD+rdSirom/x4VEPYAvUWLFvHSSy+Rl9eyXui0Fdu59/1FiQta3PfBYqat2A5oFb/JH6SyzkdwNxudhyevAGB5CwcH2Y5AZ0NSmKOtrd85BMTEhVuYMHcjf/5gMSu21lDvC/B/H0VOS7Kuoo7tNU1RkSux+HzpVv74zgIAlNLhisf85bO4+9iNhh21kiwNvgDba5q46z3vZxYMKn77+lxmrqmIeYzqhpYJYec5/vD2fOaV70p6n7EPfsHIP0+m1tXg1jX5YzpsN1v3psEXoLYpvF91g9+zI7G9upEFG6vYVNnAja/O5abX5sasz8Zd9QBU1vkiOhAz11awtkILrx01jVTt5r0C2F4TP8NCblZqtVs3RkCkgLrGALvqfdRZL+rmyobQ0Hp/inpkDb4AO+viv1y7y8+e/oanpq6O+nC9CAQVT0xZxc+e1lOJHzT+Y85+YjpD7vqYv32yDICtVQ38+8vVKKXYWdvEk1NWJhV1ZXfoWnon3YIlGFQ0+HTD8+TUVVEN5pNTVrHVEuhN/sj0CEs362O1zc9KeN7ynXVc8uyM0PIrM8JTtvvipF3Y5rJBVzX4eGrKqoSCNpGGtbmqgTdmlXPW49Nj3veWamk222sbeembdVz23IzEhV2U76yPWB5+zyec9I8pgM5z5OU8rqr3UdMQfj83Vtbz5w+iRyxnpAvTV+6Ie/7xpw3iuuMOYHtNE5V1Pobc9THlO+u56IgeDOlazLIt1ay1OhtBRUib2B2aAkH6dSyIuT0/a8+6jY2ASAGNViNi91Bt1bOirgmfo4FJNheLjVKK6gaf58e8o6aRDa4Panf435wN9P3DB6GGEyDdisc+5eGpXPzMt3H3d/Y8bZvt3PW6F2mbYy55dgZ3v7eI8p313PDqHP78wRK+WrGDWWt3MmXZtpiNlq3wO+vWHJY6BESTP0hlvQ9fQFn19nPW49NZsCHSDmz3HN3ntIXN2h11odDKWDz71ZqY2wbFsH9DtNnhrncXce8Hi3l33kZmrfXu/S/bUh2633YcvZtNlfWO397aya663RMQVSEB0/xsweU7ww3upsp66poCIe3v7Menc/l/ZkbtU1nvi+jA/N9HS6MEDeh7kkgDLcrNpHs7HZI+5K6PQ+tL8rLo27GQZVtqWFdRh317Y0UpNYfczHROH6qjGstKcrn0qJ6R240GsX/h1fNrstaV76xnzfba0Afa0BSMKF/bFGBLVQO7kuz576xrYvX2WnZ59Or8QUVQqVYb9/DHtxfgCyi2VoUbpzZ5upe8ZkddKOY7dl1jNyz1ViO7aJMe1b6jtonv1ukG+Of//oYzH5vGRc98yxNTVrGpsp5znpjOAxPDph07EqWmQY/z2FqdvOnlP9PW8PdPloeW735vkWeUyKn/jIxCsQcu1Vl1n7t+Fze9NodvHdrGG7PK4z7LtTtq6dvBu3foC6iQxglhoVBZ7+PqF2eF1lc3+EJx9ne+u4gzH5vOfR8s5tHPtNmtwRegst7Hj/42hStf0PtlZaThCwSj6rZxV/i+nfrPL9lS1cD2msaQKdA+v5udzWgIK2r1/olM5vd/uIQPXQ5e+5oy0oSvV3n39hv9kQJ7V72PaoeAcAoZJ5npaRHlvMjLygiluXDSJi+T/h0L2VbdyNLN1QzsXBT3OIn41wWHMO7ATgCMHdiBIsvcWZiTwaE92kSUzdpDvgcbIyB2g521TSzeVEW948NWSkWYIaoafDT49HJTIEijQ0Csr6hjS1UD65JM/9vkV9b/aKFk94Bby4JlfzzVjeEGok1e8tORxjN3NfgCEdewrbqR6oboj/X+D5dw54RFfLu6gkc/Wxlab/dFP1u6lbMfn86Ieyczr3wX/5uzgaenrmLC3I0xz33HBO0rGNK1GIAvV2wPNbgHlRXH3G/2Ot0b31Wne6hnPjaNt77bwNTl2yPKDb1rEsGg4tHPVkQJnsp6H+0LsiPWLb5rHH8582CAkDD+aMFmDrv3E6556Tvemb0honxFbVNI87Tv4RNTVvHAxKUEg4qTH57KkDs/jtgnMz2Nm9+Yx9C7JkX4XZwaREVtE2Mf/ILh93zCH9+Zz8kPawe+uzPy0MdLGXb3JL5dHdtv4a4vQEZa7Kamss7H41+s5JcvfRex/jvrnmdlpLG9Ovw+OZ3BtoPfviq3iWnVNm8Hd2Z6WkJTaX52Oh2LsqPWl+Rl8qMDO1KSl0mjP8hhPdvGPU4iTj6oM389ZwgXjOzOXacPpjBHf2d5WenkuiLqVIsNqy3DjIPYDWynVPmuevwBRUleJlX1/pBDetfOCq4873QAtm/bSnpaOm2s2e0+/vxLdjY4tIlGP0GlQi8H6AR8GZmZHHTIiFCvwolSigUbquhUnBM6Z70vQEaakJOZzqZd9dQ0+ulrhXI6qW30k52RRoZHj8SphTh7kE0ubWn6yh1c/eIsLjmyJ/+YvJwJ1x7Fr1+ezRXH9KZLSez4/gZfMMIEFa9Bn7Yy3AB/sWwbx/YrDS2/NjMcOfT50m08NGlZaHlYtxK6tc3j86VbGdK1hDYuH0GHohwuPLyEd+dtDDkhHzpnCC9+vZb/TF8bsz6gTWzxfEmTl2zlgYlL+XrVDl64fGRo/a46H31KC/j61rE0+nV8f25WOl1KcgEY/dfPmX7rcaGEbO/P3xQVNvnHdxYwzbKduzsKvW/7wLM+WRlpoeOsr6ijZ/t85pdXMmvtTrLS00LP1W54P1m8lYraJj5bujXi+SulQmayyUu20KkohzEPfs5rVx3BI58uRwE3HN+PzsU5dCzKYcGGShZt1Ka69BhmLoBvVoe1A7cG3Ls0n9XbayOErXMQ2uTFWznvyW9C23fV+aKiicb0L+WzpdEar7tc97Z5tMnPCpnm8rIy6OChQZTkZdGjXT7//cXh3PrWPE4b0oXnpun7ct5h3Zi+akfINzGmfyntCrL5/bj+jLh3csRxjh/YkaMOaAdAQXYG956hQ57zrcFyeVkZHNarLb3b55OZnhZhGt1TGAGxG9jvsh1Z4bYVl7Rpy2sTdU/ssYfuJy8vn4uv/jU92+VTlJtJ1cbKUI9u5TYdite3QyEi2rH96aef4UvLoqjHgfQuLQg5Z32BIEop/EGFQrGpsj4UirfKOs7BXUtCzs1Gf4DsjHBPRCkVOl9hTiadi3PIyUyn0Rfgly/Oonu7cJTTz576hum3Hkfn4twoc8NNr82hst7HPyZrk80vX/yODbvqueu9RYxPkNbEqTG8O3cj2RlpId+NTZu8zAhT1cXPfMvEG0Z5Hm++y2fwxqxySguz+eM7C7jw8B7ceEK/CKF05iFlLN5Uza46H7OtBqFb2zwO9NAihnYrYfGmKi47uhePfb4yZAe3+eXoPjz2eVjD+XK5boymLt/O/+ZoDeCpqatYvrWGQ3u0oVNxZKPj7KXOL6/01KZOG9KFd+dujNBY3AI7Fk3+ICV5mWypauSOCQsZ0q2Eh61n1qc0n5WuXrbd67/02Rkc1jNs4thVFzbfTFm2nYamAIGg4szHwinnv11dwU8PKeOenxwUYaara/Jz+XMzuOsngymzBGLomq1nV5ybGSV4e7XLZ9W2WjbsCms7tjkS9HN2Co/Keh/frd0ZMeDt0qN68dWKHRH3q7bJD0rb+e1jT/n9GCDsM8vPTvfsmNmm1kFdivjftUdHbOvXsZD7zzyYwXdMpKbRzxWjenNkHz347atbjmPl1housvx3T1/sOfQgZIbOy0qnKCeTT387mj/9bwFLt1STHkcTSwXGxLQb+ILJO5ntHtSieXM45cSxHHroodxwydls26ITdb30zBOccdzhDD9kKGedcy6Ll6/ksccf59+PP8o5Jx7D2x98EhJEFbVNbKpsiPBnBOP4HtwNjrNsdUPYqbezzseHCzbzxBerGOXoqT/y6QqCQUVVvY9sx4hWt2Nzw656ykpyafIHmb8hMqzx+rF9I5bfdWkNt540IKrezoyYNu/P30SdR6ijOyJl+qodTLUa6he+Xsshd0/i2Ac+B+Bv5w5h3ODOocij/36zjuyMNHIy0znt4C6MHRAeMTzxhlG8c81RLLjzRK4e1Se0/vDeYbPCVaN688/zh4WWnb3V61+Zw/WvzGHBBu1vKc6NNtM5e6k1jX5P2/iZh5RFrXOTm5nOn8+IHnhXWe9ji2W++mLZtpBwAGhfkB0ycXkxY024MbZ7sLbA9NK06poCvDGrPMo0tr2miclLtjJ+QjgcOBhU+APBUGhnpcs8BNDDchKX76wPdZBemL425Ndzp6GoqGviv9+u48dDuvDmL4/g+rF9OcYaneykpkHf5yP6tIt57flZ4ZHXHQqz6VOq6+I2+zgZ0Elr63Zdnd9LWUluxHcVC1ujPNJRt9+c0J/LjurFaUM6J9y/NflhaRAf3gKb57d490Z/AH9QhV6QLr4AdW0HsemIOxLum5mehkJx/59+z4fvvUvnTh159dVXefrv93Hrff/g2Uf/zgfT5tCuuICKigoy8wo56+eXkp9fwEVXXQsQEWe9vaYxZnQKaC1B0LZZtyPdPfgpqCAQDIbWXzOmD1ce0ycUufHSN+soys0kqOB3J/anfGd9SKV284tjenHnu4tYsjlSHe7ZPnLsxYMOc1BZSS7nj+zO+Hcj4/VLC7NZtiWyAZi9bmdEnLuN21wwe93OmGaNshJdF6fZydZecrPS+dfPD6H/H3VUUXdr5HJmehrFeeGP/a9nD+Ho/9PjF4pyMilyNPzrKuoQgbtOH8zt1pgHm2IPP46zl/rKjPVRaaGBKK3DZkSvttxx2iDu/3AJvz6uryNqCH4ytAvvzIkUxMf0bR+hhbQvyOacw7rx5w8Xx4xYGt2/lM+XbuOVb9cB+h14csoqvl1dEQo4cNLgC8aM6Jq0aAuVdT6KcjM44W9fsKmyIcJxv9blj7Pfm/KddRzWoy1rdtSyuaqB0f1LWbWtlnUVdfTrWEDHohymLt/OjNUV1DUFOKJPOw7t0ZZDe2hBbtvun7poOBPmbuTTxVtQQEluJleN6k27gugw5TwrYuib28aSk5nOsi3V3PfBYnq0iz2OaGRv3ajb715WerQwuXbMAZ73zWZotxI+uenYkEAC/d786bRBMfdJFT8sAbEbKFTIEezsweZmptGntIAtVQ1xR1Jmpgt1jU2sWLqEk8adCEAgEKB9B53jpe/AA7n1uisZc+LJHHfiKdjNSG5WOm3ysjydvpvjDLbzBcLurEafbvzT08QaWapNCj3a5rG2og6lFPVNARTw/GUjGNWvNCrG3jahFOdmUlqYzXOWVaEgOyN03b3b5zOmfwfufHdRyKlrX3usnEN3/2Qwh3ZvE2ECsym1HLoDOhWGBM76irqoXqabq0b15o1Z5THDDu1Gv22e99iF7Ix0nrjwUAZ1LooKK3zlysPpXJwTMjMApKUJo/q25x/nDeWBiTqssme7fI7tG+4t9m6fz6rttRTlRAsIEeGlX4zkgqe/8XT+ZmekxaxrQXYGB3YpDvk6ZjvML1eP7kOn4lwe/0I/u6MOaMfD5w1j5H2TQ/4Lu2EsysmMKSBG9dUCwhY2fUoL+M9lOqfX+oo6z4F+8Xw0Q+76mJ8eUhYybc0tr6Q4N5PKeh8/efSriLIl1nVvr2liVL9cHjxnCO/P38SPBnXk5jfnsa6ijiFdS3jg7CH88Z35vPi1FmK92ntHi3UqyqFbm1xqrW+4ICeDG47v51nW9gXYKTkO69mWt351lGfZiTeMoq7JHxIM6ZYKkZkR3Un57Yn9Y9yZMAfEiHbb0/ywBMRJ97d41/kxRoL2bp9PfnYG3dvmsbW6kTZ5mVQ1+CnIzqCuKRCKFElPE5QK0qffAObMCo8h2FbdyKbKeh75z6vM+mYaX3z8IWQjqxAAACAASURBVE/+46+8NVmnVchMF7q2yaVNflbIv5AMTq2hqsHHsi06HK+itink0M5IT0MQAkqFwjftSJ60mL3v3AgBeWz/Ut6ft4k0gdtPGxSR3+akwZ34cMFmRCRiINnk3xzL2Ae/AGBU3/YhM4KTQ3u0IdcaFDSsextOPqgzCzdWMnFh5OCoO04bRP+OhaEBeaA/6IO7FkeYes47rFtoYJrdG2+TH26sX77i8IjjnmiFHbo53Oohup2pIsLpQ8t48eu1lO/UprbODkd9/06FrNpe6xmBBnDUAdFmEJv87AwKHFrGdWP7hsxEeS4B5oyS6lCYExFhl5eVQZv8LJbcNY77P1rCk1NWhQSdl+nL5oxhZaHR2FnpaXRwmP66tc3j5nEDokaYJ+Kt7yJNUMf2K2VUv9IIzaMoJ4M8hzmna0ku3drmcfWx2tRna7wHWxFp/RzBGG6N1X5cuVlpIRMO4DnJzgmDOjJp0ZYI81Ai+neKDARJC2kQ+7cVf/+ufYqp9wWYV74rbjhctvUCZ6TrFy83K4OORTnkZ2fQ3qG2povQrjiPqp07mD5dN/4+n4/lSxYTDAbZvHED5/14HL+9/W6qqyopyxe6d2yHv6EOEfF8WeO9fDtqmhAk1DP3BYI0+gMRQ/nT04S0NPAHFJV1PjLSJCrax02/ToURjZWd4fOXo/swpn+HiB73GMuW3+QP0s5xXKeT0hm19ftx/bnh+L58c9tYXrh8BCcN7sQxfdtz4/F9uW5s3wj77d/PHcrcP/2IS4/qxZGOxjUjTfjJsLIok8yw7iVR57Z7pz8a1DGuLdqLWFlB2+Vnh87jzJdjC5ZCD6dnIirrfRF27xvG9mVIN3097pG1tkZQmJNB2/ysiDBVW5ikpUnIRm5nSS3K9a7Xjcf3o01+Fn86VZs38rLTozoPVx/bmw+vP4Zj+rZnRC9t0rGLDOlazB9ODieAtOsN0KNdHl3b5IbqfdahkXM3nHtYt4j36ZeuTLu2X+WgrvqY/R0CorQg2n8FkJuVwTnDu4XMWvkeAuKf5w9j+q3Hxc38moiQBrGfC4gflgbRTOoswRAvgVY8P4DzBUsToSg3m7ffepPrrruOyspK/H4/119/PWec25drf/YrKisrCSrFddddT8fSdpx5xumcddZZTJgwgYcffpiS3pHOxA5F2QRVOFeMk131TZTkZdHosHUudfkF0tOENBF21mlh4u5FuiNcinIyaF+QHcp7A7rnV1aSy0FlJbg5+aDOPP75Sg7qWhwSPHYIro2zB+dOtT3K6lXa2GaWnw4r4yfDvJ22H91wDG3zs8hzNZwdi3J46RcjI+zdZSW5PH3RcA5vpnCw6VKcw8FdI6/bFp5lbSIjdS48vAftC7I5abC3ZgIw6cZRnPC3KVHrA0EV+S6lCW0tX0ZedqQGkZeVwTOXDGeIVS/n2xnxprosQD5/eIVIuMd9/fE6uMAOW/Z630WEgZ2LeOHykdz7vh63cutJAzmgQwFjBnQI5eMCuGZ0H658YRb3njGYUw/uwu9en0v5zvqodN4/HtKFm8cNCI1g79+xMMrcd/Wxvbn9fwtDjuHDerblvp8eRFlJbszGPTcznayMNI46oD3Lt9ZE+GxscjLT6Vyc67F38sQL692fMALCA6UUW6obQx+U7Ry2nb6gVfKORTlJ9zLuvHN8qOyUKdGNwJdfRueP79evH/PmzQstV9Q2kZ2RxoZd9TT4AmSkpRHvPczJTAuNzrV9Bc5rsAUE6B5cZXXkBzj5N6OZvW4nD0xcyrSVO0IjRp2NemlhNl/dEjmPxWMXHEJOZjoF2RlM/s2xgG5EinIyoob5NCfP/5gBHbj62D788tg+Mcs4Bxk5KcnLYmi3aCF2/KCOUeuSZdqtY6PW2SYkW4N54fIRVNb7SEsTTjk4fgRK346Focb5qlG96dEun9ve9g6q0Ga5bVHXCXDcgPA1/fHUQUxbuYOt1Y0EHDd/WHcdvjrYMikO7FzIt2sqaJOXSZeSXBa65m63G8xEDd+vx/YlKyONi4/sGXq2bR2a9I8O7BSRNvyKUb35eNEWerSNNDP+9JAyMtLTQlreOYd1izrXhUf05MIjeoaW09KE80d096yXfem2Jja6fynPTVtDz/bR5s3W4IRBHXlu2pqUzBO9J9m/a58imgLBUHI2J71KC0J+AC+7eTx2R121se34du8uI13I8XDu2mSlp9GtTR7baxpDAiJNBET3Sp1pjDPSves3rHsbXrh8JPPKd9HL+pi6lORy3IAOXDPGe3Kdkw4KN4TO625XkJ1Uor9Y5GSmc4tHOKwT2wl88ZE9mbN+F0Gl+GrFDkri2NhbEzs6xW64j+mbOKzRiS3ATzqoM0O7lcQUEHaPvrYxfj6q9gXZ/PHUQVz38mwCjrDscYM78eXNY+jaRtvqbz5pAL8acwA5GelUNfiiHM+dLYHn1pjcFOVk8rsTI5+RbXbz4rCebfny5jFRPXbbNNq/UyFTfz8mZIpqKc9dehgvTF9LTqYWWqP7d2Dq78ekbH6NP54ykKuP7ZPQZLuvk1IBISLjgH8A6cDTSqn7XduLgReB7lZd/qqUelZEugHPA52AIPCkUuofqayrE3cET1FOJvW+ALmZ6WSkpyWVuTOVhCIl0oS0NCEvK4PMdIkayJaVkUZeVgb52RnUWFqQQqvrdk/XdrbGS4WQniahHqd93GcuOazZ9W6Tlxk6308PKeObVcmla0iG353YnwcmLg01AO0Lsnnh8pHUNvqZuXZnynqKbi4Y2Z1Ji7YwvMfupV+wzWnv/frokN9iSNfiUDitHQyQTB6qLEv4+wOR77UtHECbpmyznFdCuA5FOTx/2YiQL6c5JErR4qxHqM4OzbI1GvFj+pZGCetUTr6UkZ4WMzR5fyJlAkJE0oFHgROAcmCGiExQSjmD3a8BFimlThORUmCpiLwE+IHfKKW+E5FCYJaITHLtmzRKqaR78EFXLqU0EXq2zw8dY1AzE3P1bJdPKygPEXRvm0dlfVPISW2HxM0r3xWROsHpxM5yaBqZ6Wkh55ktC2MoEK1Kr/YFZGXoOPeHzhnaqse+ZswBnhpNfnZGRHqOVDO6f4dWmXmtxIqwGuwY2e0ctWtHmx2ahCCyR98mO/lPLLNfMoO8vPBK55KI5kQQGVJHKjWIEcAKpdQqABF5BTgdcDbyCigU3XoXABWAXym1CdgEoJSqFpHFQJlr36TIyclhx44dtLNyICVi+ZaaiAyRdsRGS01ERSkwbWRlpFHqMa5gUOciRHTq6fQ0ibAXZ6YLbfKyolReZWWArancSU5Oans8d//kwJTNh/F94eUrDue1meWhyetj0bu0gG9uGxszWseJPSK9d2nyWtSFh/dgdP89J1ht7BQZRkDsG6RSQJQB6x3L5cBIV5lHgAnARqAQOFcpFREoLiI9gWHAN3ggIlcCVwJ07x7toOratSvl5eVs2xY/PTVo7cGZAhl0wyq79k9V0TU7JgDukRSbdtYTRJHRrph+vXuktD7uyCJDNCN7twuNxk1ER49Ecl4M7VbC85eNCIXaJsPdPxmcdNlkmHjDKE+HupvMdJ2Ty2vgpGHPk8ov1qvL7e4+ngjMAY4D+gCTRGSqUqoKQEQKgDeBG+x1UQdU6kngSYDhw4dHdU8zMzPp1atXwsr6AkGWbanmiucjo4m6t80LJfH6PnKSlZhszp8OIjNzzzhyDXuelpqHWgv3QLJYZFkCojnRbYbUkcqnUA44Y9O6ojUFJ5cCbynNCmA1MABARDLRwuElpdRbKaynNXvah3zpyu0PJD1Xw/6Kbcv2SgFhMOxpbMHwfRlHsL+TSgExA+grIr1EJAs4D21OcrIOGAsgIh2B/sAqyyfxb2CxUuqhFNYR0Nk8AZ5PMA/A95EXLh/BhGuPiplaw2DYk9hhzLFGdhv2LCl7Ckopv4hcC0xEh7k+o5RaKCJXW9sfB+4GnhOR+WiT1M1Kqe0icjRwITBfROZYh7xNKeU9I8puYseub9hVz7nDu3H28K5UN/hp9Ad2e0Tlvk5JXlZoMJLBsLc5e3g3zh4ePSjOsHdIqZi2GvQPXOsed/zeCPzIY78vacks5y3EOXjrnMO6Rc0DazAYDD9EjCcIItJC99pDA6oMBoNhX+cHLyD8gSDnHRYOj0006tNgMBh+KPzgBURGelpEfp/WyJlkMBgM3wdMqIDFV7ccFzUJjMFgMPyQMQLCwjmRjMFgMBiMiclgMBgMMTACwmAwGAyeGAFhMBgMBk+MgDAYDAaDJ0ZAGAwGg8ETIyAMBoPB4IkREAaDwWDwxAgIg8FgMHhiBITBYDAYPDECwmAwGAyeGAFhMBgMBk+MgDAYDAaDJ0ZAGAwGg8ETIyAMBoPB4IkREAaDwWDwxAgIg8FgMHhiBITBYDAYPDECwmAwGAyeGAFhMBgMBk+MgDAYDAaDJ0ZAGAwGg8ETIyAMBoPB4IkREAaDwWDwJKUCQkTGichSEVkhIrd4bC8WkXdFZK6ILBSRSx3bnhGRrSKyIJV1NBgMBoM3KRMQIpIOPAqcBAwCzheRQa5i1wCLlFJDgNHAgyKSZW17DhiXqvoZDAaDIT6p1CBGACuUUquUUk3AK8DprjIKKBQRAQqACsAPoJSaYi0bDAaDYS+QSgFRBqx3LJdb65w8AgwENgLzgeuVUsHmnERErhSRmSIyc9u2bbtTX4PBYDA4SKWAEI91yrV8IjAH6AIMBR4RkaLmnEQp9aRSarhSanhpaWnLamowGAyGKFIpIMqBbo7lrmhNwcmlwFtKswJYDQxIYZ0MBoPBkCSpFBAzgL4i0styPJ8HTHCVWQeMBRCRjkB/YFUK62QwGAyGJEmZgFBK+YFrgYnAYuA1pdRCEblaRK62it0NHCki84HJwM1Kqe0AIvIyMB3oLyLlInJ5qupqMBgMhmhEKbdbYP9l+PDhaubMmXu7GgaDwbDfICKzlFLDvbaZkdQGg8Fg8MQICIPBYDB4YgSEwWAwGDwxAsJgMBgMnhgBYTAYDAZPjIAwGAwGgydGQBgMBoPBEyMgDAaDweBJQgEhIqeKiBEkBoPB8AMjmYb/PGC5iPxFRAamukIGg8Fg2DdIKCCUUj8HhgErgWdFZLo1B0NhymtnMBgMhr1GUqYjpVQV8CZ6VrjOwBnAdyLy6xTWzWAwGAx7kWR8EKeJyNvAp0AmMEIpdRIwBPhtiutnMBgMhr1ERhJlzgb+Zs0RHUIpVScil6WmWgaDwWDY2yQjIO4ANtkLIpILdFRKrVFKTU5ZzQwGg8GwV0nGB/E6EHQsB6x1BoPBYPgek4yAyFBKNdkL1u+s1FXJYDAYDPsCyQiIbSLyY3tBRE4HtqeuSgaDwWDYF0jGB3E18JKIPAIIsB64KKW1MhgMBsNeJ6GAUEqtBA4XkQL0HNbVqa+WwWAwGPY2yWgQiMgpwIFAjogAoJS6K4X1MhgMBsNeJpmBco8D5wK/RpuYzgZ6pLheBoPBYNjLJOOkPlIpdRGwUyl1J3AE0C211TIYDAbD3iYZAdFg/a8TkS6AD+iVuioZDAaDYV8gGR/EuyJSAjwAfAco4KmU1spgMBgMe524AsKaKGiyUmoX8KaIvAfkKKUq90jtDAaDwbDXiGtiUkoFgQcdy41GOBgMBsMPg2R8EB+LyJlix7c2AxEZJyJLRWSFiNzisb1YRN4VkbkislBELk12X4PBYDCklmR8EDcB+YBfRBrQoa5KKVUUbycRSQceBU4AyoEZIjJBKbXIUewaYJFS6jQRKQWWishL6ISAifY1GAwGQwpJZsrRQqVUmlIqSylVZC3HFQ4WI4AVSqlVVoK/V4DT3YcHCi3tpACoAPxJ7mswGAyGFJJQgxCRUV7r3RMIeVCGzttkUw6MdJV5BJgAbAQKgXOVUkERSWZfu35XAlcCdO/ePUGVDAaDwZAsyZiYfuf4nYPu3c8Cjkuwn5fPQrmWTwTmWMfqA0wSkalJ7qtXKvUk8CTA8OHDPcsYDAaDofkkk6zvNOeyiHQD/pLEscuJHHHdFa0pOLkUuF8ppYAVIrIaGJDkvgaDwWBIIclEMbkpBwYnUW4G0FdEeolIFnAe2pzkZB0wFkBEOgL9gVVJ7mswGAyGFJKMD+KfhM07acBQYG6i/ZRSfhG5FpgIpAPPKKUWisjV1vbHgbuB50RkPtqsdLNSart13qh9m3txBoPBYGg5oq07cQqIXOxY9ANrlFJfpbRWLWT48OFq5syZe7saBoPBsN8gIrOUUsO9tiXjpH4DaFBKBayDpYtInlKqrjUraTAYDIZ9i2R8EJOBXMdyLvBJaqpjMBgMhn2FZAREjlKqxl6wfuelrkoGg8Fg2BdIRkDUisgh9oKIHArUp65KBoPBYNgXSMYHcQPwuojY4xA6o6cgNRgMBsPeonoLLHkXDvtFyk6RzEC5GSIyAD1GQYAlSilfympkMBgMhsS8+nMo/xYOOAHa9EjJKRKamETkGiBfKbVAKTUfKBCRX6WkNgaDwWBIjsrylJ8iGR/EFdaMcgAopXYCV6SuSgaDwWBISKBR/w/6U3aKZAREmnOyIGueh6yU1chgMBgMifE3Wf8bU3aKZJzUE4HXRORxdMqNq4EPU1Yjg8FgMERSVwGZedBQCfntoWYL+Bv0Nvt/CkhGQNyMnm/hl2gn9Wx0JJPBYDAY9gR/6QVtesHO1dBhEGx1TK4ZaErZaZOZUS4IfI3OsjocnX11ccpqZDAYDIZodq7W/7e6Zl7eGyYmEemHTrN9PrADeBVAKTUmZbUxGAwGQ/NIoQYRz8S0BJgKnKaUWgEgIjemrCYGg8FgaD4p9EHEMzGdCWwGPhORp0RkLN5TgRoMBoMhVQQD8ben0MQUU0Aopd5WSp2LngL0c+BGoKOIPCYiP0pZjfYGj46EqQ/BwnfghTP2dm0MBsPeoqkWHj8aymft/rHe/w18+Td44aew+D29bsJ14d8718C/joSarXr5uxfgPQ8jTSBB4oq97KSuVUq9pJQ6FT039BzglpTVaG9QvRmqNsLrF8PKTyHBJEoGg+F7ysbZsHk+TLp9948142n4ZDysnAyvXqDXzX8DVlizJUz/F2xdqNcBTLgWZj4T3f4EEwiIvaFBeKGUqlBKPaGUOi5VFdor5BRBY1V4OZFKZzAYDC0h6I9sa7xo2BW5nEiD2FcExPeW7GJorA4vJ5LYBoPh+02qrAhBf2Rb40XlhsjlRCakgBEQqSW7EBocUj2RxDYYDIbmohSoQGRbY9NUG/7tTsKXSED496IP4gdBThGs/TK8vLvJr9ZOh61mLKFhH2fbUlg7bW/XonWpWBX2I859FZrqWnacoA9mvwTBYOKyKyZDxeokjmm1K43VMO91aKoJb3NqDVUuATH7pfjHnfogfPWPxOdvAcmk2vj+k10Uuby7AuLZcfr/+MrdO47BkEoeHaH/f5/e08eOBl8tXPI+vH0lrLsETmtB41k+Q/91GAhlh8Qv++JPIT0bbt8av5zdrmxdCG+5JvlxCoWabeHf62fAF/fHP66/Hib9CY66Pn65FmA0CNAmJifGxGQw7J/4LFNNlTUBZtWm3TteokFotoaRjB8gVsfT3xCpQfgdMzoncmjbXPNtcuWaiREQAFl5kcvGSW0w7J+kZ+v/ITt+M53Nbud0Ivu/r9Z7vZeTO5aA8NVD1QZAIDNfLzeXorLm75MERkBAtJ0ykLoJOAwGQwop6Kj/V22IXy4WyhXinsia4OVwBm9hEOtYvjot0Ao6aH+orwV+k+yC5u+TBEZAQHTYWbJqXSKUallvIJX4m4wJbV9BqZY7UePhq0/OuWrjb4ruFPkb98/xQAUd9H/bxOQm4NfX5nXN9vaI5QTfirPtcEYTeWke9bui14E2MVVt0FpAZi74HGYt95iIPYwREADt+0YuPzUGNny3+8f9+jG4t5Meqb2v8Jde8M8ETjfDnmHmv+HPnWHX+tY7pq9Bv3Of3pX8PveUwuNHudZ1gDcvb7167Sny2un/sQTEcyfra7unFJ48Nnq7u+efyMTk7Eze08Gxn4dgqa/wPoavXvtKirroSYHsTuV3z8Mbl8U/f4oxAgLg6Jtg2IWR69Z/s/vHXWANoW/NBmB3aaqBXev2di0MoHN/QTjPf2tgm1bmv9m8/bYtiV638O3dr8+eRlmak93Iun0Bzu96y4Lo/aMERHNMTI5zee0Xa4Ccr05/l9lFlgZhaZWJwlsBfv4W3JS6kPqUCggRGSciS0VkhYhE5W8Skd+JyBzrb4GIBESkrbXtemvdQhG5IZX1JD0DDhgbua5Vhq+b5LeGONiNV2uO2rV7zgWlLT9Gc8xT+xp2A9/S0cW7o0Ek2i+mgGjQAi0zFzJywpFTyZi6OwzUmkeKSJmAEJF04FHgJGAQcL6IDHKWUUo9oJQaqpQaCtwKfKGUqhCRwcAVwAhgCHCqiLjsQK2MHf1g06oZEvfB5H9NMaIvDPs3tgZhO2tbQgqzg6Ycu4Fv6ejivSIg6sICIjMvrEHEcoA7cbdbrUwqNYgRwAql1CqlVBPwCnB6nPLnAy9bvwcCXyul6pRSfuALILV5uNMzI5dbYxIOsTSIfTE7rDvfi2HPY78f0oqaph3emb8bGkQKc/ukHNu0E7oG17eXlSDax+2Yb46TOtF+cQVEnRYOmblh81iinE0AGVmJy+wGqRQQZYDT+F5urYtCRPKAcYBtOF0AjBKRdta2k4FuMfa9UkRmisjMbdu2eRVJjnTXjd5TJqb6XfDKBVC7oxXO1wzcw/m/T2z4Dt65Zv82lThRSs8tsO7rxGVtDSLNSpJQsQre/EXzetTOd/+ZcbDFNQfygjfhqeP0exvw6XkNXr9Up7H+8Jbosl88oBu7Vy+E6i3J1wN0SuzZL8LEP8DySfpatq/Q2zbMggm/juyA2WOY7Ot1d84SaVbuMVDu5WmPwJz/hpe9evkL3vIe/RyrwW+oBBRk5mgBsX2ZvreNSYxwz8hJXGY3SGWqDa/WMVZX+jTgK6VUBYBSarGI/B8wCagB5gKegxOUUk8CTwIMHz685V31HkdBt5FhJ9aeMjHNfAaWvAft+sAJzYg82V0avkfpFdy8dBbU7YDjx++eLX5PkSicNOjXcwvMeDpxWgz7udrv7/9+rfOMDbsQentE7XjhFBDrpsPar6Cjwzo873XdOAPUbIH3fwsrJsHCt/S6kxyNox2Fk1MEiyfoBvqUvyZXD4CJt4Z/T39E/9+1Hi6fCM+foRvRE+6C3DZ6m91z98cIL7fLxSKRienjP+j/Q3+m/9d6pNdY8Kb+pgEycmHgaTD/tWgB0W8cbJwT1vpsDQLC+yciLbXZklKpQZQT2evvCsSIPeM8wuYlAJRS/1ZKHaKUGgVUAMtTUkub9Aw42fHittTE5Oy1JmNisjWXFGZkDOGsx544395CrNda7eMahP08EuX+shtsSeJztcu6TS0ZLlt1PO3K3Si67exO7dNXH91IeQk8e10y15AIe/RymnUs57XY9zLWPU10/uZGMXmZap2dr/NehLHW5EPO+5jbFn72KhxyUdjnYDupbbofGf/c0LrmSQ9SKSBmAH1FpJeIZKGFwAR3IREpBo4F/uda38H63x34KS4BkhKcfoiWOnEjRmIm8fDsD3dPOAadL38KJzrf6+wvAsImYb5/a3uzBIS1j/2c3Y14vHO6zavunm/lhrCpxlenO1cRx/ZoVO1nkZYe+7zJYn+b9jU5ryXq3O7Z2RII4ygfRIJn4zVi23m/0rO0ZuBeb68rLotc52x3CjvFP/ceIGX6iVLKLyLXAhOBdOAZpdRCEbna2v64VfQM4GOllLtFflNE2gE+4Bql1M5U1TVEmkNAJBNB4IXnCxhPg7DOuScEhFMo7M+RKomwG9J9PaeW3ftLmO/ffm5JdDgCbgHR5H2OeB0E9zbnt9BUpwd89Tham5d8DSCuRj/QpO3pTmwB0RoahD363D6vs76JnnnC7c2MYnLP3QCRmkJaZlgrcKb3tu9PcdfwuoycyMF0KTYfJUNKx0EopT5QSvVTSvVRSt1rrXvcIRxQSj2nlDrPY99jlFKDlFJDlFKTU1nPEM6e0IpJsYfGx8PZA0mk/q363GEKaEaD3Vit920uTrOSvxG2LdNzArQma6dBXYwRo4nYtgy2uyyJwSAs+UCbYzbP18dPNMrdboScvcnqzS2fiN7fBEs/1GmYZzwNO9fq9Urp9cGgnv9jx0p9X5d9HPtYq6fqa6hYFV5XtRHWWb6vFZPDvcgl7+u/kIlJYOlHevvSj8L7V6yCzQvCdQXd0FVtgu3W8138Hqz5KpzdNNb7tnUxbHU5pZ0N3iJL0W9/gP7vq/PQTqz7vnFOeN3KT8PXkIhN87Tje81X3tttk4ytjSx6x5FV1dXAR83vnIS/x0ntDlg9JfycnTRUeYe5OgVqelbYr2DPRS1p4XVFDgGRmdfybydF7H0RtS+R5gp1nfNfOOJXzTuGlwbhZeqo3gzPO6J+myMg3roSln4ANy2Bos7J7+cMXww0wqOH6d+tNR9AwA/PngRdDoErP2v+/l71mfE0fPg7+OlT8NYV4fVx6+zRM390pM5r05JrnfIXmPKA7jWv/RIOuRh+/LB2Rr55OYz7P/joZl327Ofg9Ut0+uXS/pHHaaqD/5waXu55jP7/1cPabn3NN3pugdMe1o7NVyxH6C8mh6/n5XOhfT8d6XLph9DjSHh4WPieODUIZyqJrx/Vf0Vd4aaFsaP0/nV49DqnacSOzul6GMx6ztsHYd935/lXWe+DW9vw4olj4m+3Bah9rE/G6/DVEVckYUJKsN1toprzov4DOOXByG21VtRkdnFkxFGEiSkz2qzW6SD9DMFlYsqFoRfooACAg8+FzfPCo9y7jdSCs3abblP2gIZhBIQT91iIlqSkCHr4ILxeSvcH2hyncai32Ew/grN8KiY6tyNHvFIYtBQ7DUVNM8Ijg45OKgAAIABJREFUvUw3u5P0zNay7F6/bSqos0KTdzi0HttBuXNttICI9bzqdmjTx4aZ4WXnu1fnCoHevkz/r3FF0CgV6aT2ume2g9nr+cfKYuyejnfQ6VpAgH7m7gYwXmenNUxMtp8vzXGsLQv1/+aakIKByPrH0zDcKXNsQZWZExYQ/sbIjpg7fB7gx/+EzkP07+zCsIDJzIFhF+g/m77Hx7+eFGNyMTlxSuT2/Vo2VsDppA5FVHi8dO4PpVmDk5T3MRLhNjG1NvYAn9bs2dg9uub4hEICwqOx2J2xETVW0kX7Om3bsrPht7d5vTvuhjMUxWTVc7016UtjdaTzM5aps2575HL9zmgndRT2vfESEDHeCWePONCkI3BsE4nPS0DEaaRbQ0CEjuU4ry1Eo4RcAie1+zuIp2FE7Ws9d2eEmDt83N3phOjvw/ZDZOZFl93LGAHhxPngispaNtrY+RLZv71MTM11hjlJNjzSTYSJKQVO6pBtuDUFhFXPmmZkxPXyQdjEio+Ph92IhBLBOcISITI9s73N691JJJTtgXCNVZH7xxqz4j5H1Ybw/Yr1fO1sp151iVU/p/nE36QbRLsx89VHm2bj9eIT9fCbo0k737P6nckdPypKqRkCwq0B2s/aGZrq9iF4aRDu+2Wbmez3aR/CCAgnTmlfXNaySUeCSWoQzY23jkC1YB9cGkQKwlzthrI1Qhlt7HvnTpkeb1InW0A0VEaX87Xgune4HOe+et2rthsoTw3C491xN9puh+3m+fp//c5IJ3Ys81jVhkjNqmJ1uC4BX/Rc6wB5ba16esxD4TZlgb6XERpEY6Tj1VfvoQ3HC6H10KKcx08mvYSN8z2zG2b3NxHwR87J4t7ub9JaZaNlNownICLmaagKH9eZD8md0ttTg3B9H/ZscEaD2MdxSvairtrG62+Cb5+C8cXJjT6O0CAC0etsol7UZph87J5soAnmvabr5rZHr/lSr7f9FcEg/Nthz4zXU/M36n3HF8MLHimwanfobc50xJvnw79G6t/1O3UqhsXv6nK2Pb2pDh4coOfJ+HNXHfWzbZkuY0e5uLF7hM4GEyJ7frXb9THsFAh2g/XyufC0K0vvA72j5wpYP0Pvv8ER5TS+WDs/p/8r+tzrv4H7umonNUQ2QPbvynIdaWbfx/HF8OKZ3tdoY5snF7wJ3zwWXl8fI8J73qtwv2Ms6msXhkNAAz7vBseef/31S6O3PTI8el1+B31++xr8DbrHnOEQEO5e+xOjdDSUF/4G7WgdX6wjg96+St/L8cXwxuXJpZewcZqYti7Ux3DXZe2Xen6MCb/W293C68F+cFcbuK8MPr4dpj0c+3xO7fP+bjDtn/p3ab/w+mdP0v9tzcGtLUC0ht2mhxXZZATEvo1Tshd3BRRUbwy/CLXbPXeLIEKDsF5W9zSGzm02zTIx2QLCpyNJIDpcdbE1VN8Oh3VrDM4G1h0K6GxAvRruHVYunFnPxi63YVZYgGyap//XboPqTTp0s6kadq2FddP0tlhzD9iCtMaVZ8spUO2w02+ftFY4euabHKGWNu65D5ZbYanLJ1nntAT6l38Lh4naTkUndkiuM9TRqUEsfjey/K61kcvxHKJ9joMT79O/mxNubY8yDjTpurRzJUH2N+nnHUvouHFG2dhkZGkHcXq21kS8NNnVU7yPF2jSYb4A898I/wY9f0qyGkQwGOmkduIVKfXd8/q/vwGG/lz/uYknHCC6E2cLwTF/gN6jI7ddNlHP1ZBvmfR+5cij5RYQwy/TZVM0bejuYASEE6fKb38YleWOkaxJxHAn66SOmtqwBT6IQFNYhXULHFvYhYSJO2qq0fs3JDat2eeKsK8mcW/shjTkUPQlnhPBvi/unqXzftlOQtsEkOg5ue3C9gfrNZdAQxW0OwDa9ok+jh3N5GxsQxrEBm/7s5N4z7z/yeFGx0tzdTcy+R0il/2N+n4PPC28rtexukGv3a6f4RHXxq8fQEn36HW2ScXOPOp1HbHMn/7GsBDIKYq+tmSDEQJNsUNm42Vs9TdAbgn0+1Fy53Hinj7Yrnt2YeR9BigdEDnHTIeB4d/uZ5dTDH3GNL8+ewAjIGJhD2Cp3BDufSfjQEvaSd0KGkTQF1Zh3QInlAfKEk5OIZCe7RIQrhff7fx0X7dd1+Y6o+2GwTaHJXPNsXqUEULNEi72c0oUKeMWRrYwDXrcq8Zqa6YvD/XfrptTQNhCMNCYuDcc7/qLysKjbb18EM4GB6KzlDbsAlRkcrq8tvoeVVrhmm16xq8fQLFHEuUMh4Dw18eIFoshIAKNYY1I0qIHmiU7H7y/IbavKyuBqSYto2XzKLi1cPvbysyN/hbi1WEfGCGdLEZAxMLWIKrKHekKkvATtNgH0ZyoIocGYb9szmH8EJ2PyNno5RRFCgV3z6jSFe9dvSly2W74Il70eIl0rW0Nbg0ixjU7Q1FjNRh+j4isZAWE+0MPCQh7shmngKjSPUSvCBP7PjgjV5y/E5kk4zlEi7uGhZKXOajDoMjlApcGYTuhcxyO6tw2er2tIbbtFb9+4K1BZLg1CA9hECuIwN8YPn+Fx1SryZqY4moQ+fH3TcuITl7ohVuIuL8TmwwPARH3uEZA7P9k5UNOie5N24LBbsRnv6jztXsNpGtxFJO7l+6DD2/W/oAl78McR65C5Yhisl+2UM/VDx/dFvYjOB3aNmmZkTbiitU6V/97N+m/T++OrMt7N8DG2eFlu6FfOTns42jyiIpxX1vo47fq/8n4sD/AaRaq3qhTSPvj9MIjQnatBqp6k04v7U606B77YJtZ3r1Bz7NgD4Cyn1PApUHkFMUIQVSu/2ifit2wu8cpuHGntHBS3DV8Tq9y7mkmnYndnI5R2ykN2vTiqw9riG2SEBD57aPXhUxMebDqC1j6fnSZWBqEU0B4ObK/+kfiOoGez3t9jPkxEk0KlKyAyHFFgXkFkqRn6W+wOQJiP9Ig9p+a7imOuh66jtC/i7vql9ltm/70Xt2I9T8JhrmcXU5hEIjnpI4x6MZmyXvwzeO69zjvVb1u6PnW8RyNvt0Y2A3pmqk6pULoPC4NIiNXmxaqHY7oZR/qXP1O2h2gG6jN87UDeuVnMH5X5LlApwsZXxnfNGD7Btx+hF3r9DVC5H1bNhFmPKVz7scKS3VqXE7hZ0cWRZR19fx8DfDpPZFOdvCerrKhKjyZfLK07a1Hk3slcotF9yP13BWHXKyffW6b+BrGAcfr+7d5gXakOzWI7IKw1pFdHF6fmRc2MWXkRJqPckr0O+Kv1ylA8tvr8/c9EfqdpN8RG3sWs8Fn6og0m7z2YaEYKxtyoCms3VRvjN6+c03sa3by4e9ib0tGQJQOgF6jYjvTQQ8IrHUER3iFBtvRXM5G/+znEp9/P8FoEG5OuAsGWvlyirtG2uNDMeZWY+vlUPM0MXk5qV09LPcHZcf9O3uANk4NIhTzXxW5X6isS0Cc859ox6A9Q5eTSz+C8xwzZzl7yV7CIK6ASGKOXef9sE0z/obYjWREZtoE40HcUUD2HMBuQgLCcezGRALCwyGenqV72W7TnM3wy6PXtesN5zyvHZun/k1rVF4x9Db5pXDWM9BhgLXsFBCF3r9tn8aOlVoDcU5Xed5/w3m9+p2oG7lzX9S29BPujDy3PTDsmJvgMOtauh8JVzhyaro1v7QMOOAEfW/jPa8uh8Dpjg7OwB/HLhuLRCam9Aztj7n4XSjzCO21KXT5ddxmXAi/F85G/8AEsyMbAfE9oags0h7vnsbQy/zhGcXk0chFqeAq0m5rN/QFXjnhHQLCbsxCDmBX/h239pOeFW36cA8EA92D9BJOznM5idf4JzPHrvN+2L02X11sAeFlYoqFWyD66vH0mYTulUODaKy2fBAxnI5ekUr1FdEmICdu0wU032lqPxv7/BGmJMdv57nsa9ixIjw4K3T+zHBnI1aUl1dd7fP6GyL3i+owiDbr+Jvia0Zuf0+ixt6LZHwQyeB2/Hu9v24BkUwywtZMN5Ji9p+a7g2KyyIjSOxGKdTgJdIgbBOTRxST56TmjuPZDX1uSXQ5Z5iruy7uAXOhCCzHzGK1rjEFOzw0CBHvkbjgHXYZT4MICbEkNQhbgPkavM1zENvE5IU7CshX551W2SuKCRXHB4E1qtjVINXtjMzz78ZL8DZ3bmH72dgmRqcPx9lAOp+hfQ07lkfXLy2DkDbk1lzcy07Nwz5+lIDwaEwzsvU35HzW7oFkOa6IsZYMHks0nqClAsIr+4BbQCSTReD/2zvzaDmqOo9/f6/7bSHLe1nJvkBYQkJCCJFFATMOJEHABJUQkYyADDgIKOCAuJ6DMwMuZ0A5KAqjAyqOCiPHUQTRYRAcIBACRLYEMCY8SIBhEUKW9+78ce+v69ate6uq36tOv9fv9zmnT1dXV1fVra66v/tb7u9X4ypwRSICIo3hzkO0y9zcbNN+5zU9C9fGFhDccW38X/27TSZb58vPJDtyIP5QsQbhnZFqCQi+abc+qScecUZQ5u1XgK610bmUWvNXWnNv9rdf1QXZXTvxKxv8HQIf880u/Tt3RrJN19pomSfF7dwWnky28T5tZ3/pT/HJVu7IGAA2Of/Rmy/qeh8u29/Qzk930l7rsMjW7FJqjtJXVPbzeoaA8AjecsacCRcWAvwf2Z2u3UHawshug1eDYAHhahCuwAhpENZ2rm2fSP/ulfXxlB6usGwdFheWWSGrPlyB7dJbAeE9Vi80iAHEwDGG1QN3FqkbVbPmJv1a9Utguslh78sWuu6WqKD7mXcl0z8w9gibH6LV1ye3s2dSs31/80O6NoHL2h/r1wmm4Hu5VdtI3U6w3BYJm6lH+M/vj9cA93gKzn9zPjB63+R61m5W36BfadimvDwmpnuv0rNj3RDQ8XOTE/3u/EL884Pf9e/ziduSznpAO3Ndn0VTs9YQS83aDv/bL0XfzTs1GXZq49MgqjUxcWe+z2JgzY3AhHk6sOCV9fHopJahWiARxc1e7jyKpnJk+nAFgtuh2hFAbMLa6WgQCa2Ookgr28TZOgyYvVzX/QD0fWhrQL3SIAKmUSbPKH/Y+CixYRp8frzPNOGz/wn++6sfIxpEGu4oq3uH37xij4y5QxsWsEGHHJdAXPiEZhYD8Simndt0pMm5q6OXD+5Iy63ASdcDHVPj33OH0TEVOO0X8OJz0jG7tgGzPxhFgAH+qI88VExMKRoEkBQO564OR7BMOAi47EUdmcJc9lJYGDITF2jHMTt4px8JXLoZmPZu/bnUAhxxgV536Wbgs126mFCbiR5qH6mP+1nrf+dR55TDgf1MQEQo7PJzW/Tv33Oh/rzsO/ozs//79XEnHAScdTfwqT9pJzPT1ARcvAG4aD0w7QjggseB8x7REUg2TbYPwtUYUgREyMTkY9Hnkuu6dwJLvgq856Lo2DHHekb02D5LgDOdNC++0FybtE78mMv1fXHeGr+vaMph8c8JE1NKl/qh7+t9DyBEQKThOhpDcfn2aIlt5qFZqmn28rxpBuwopp3bdEjk6JnRy/egcudeatGjnbYR8e954lW5LRw9k+YMfqNLmwPszqPXAsJoT7u2aYEb8oW4tI0IdygdU/V3LEBGztCdflZnwlFCPKru6dEmHG4nm2Zah+pXyxBzfc05q25zXGskzB1xe0dkxghd83Jr/LzbO5NtZJNS61Ct9boDm3JLZMLqmKwnyLl28JLtg8gyMQV8EGkjcyL9PYfdctTV9jdNXqfm6FgxAZEVkdSc1BgyBURKdFjnNH1fNLf7NZFxB8Q/szmMzz/NAd1UStbq7ueIgEjDHdXteicyA9kdrO3UZA0idCOkCYGY8EnTIDh81ggIt8PwPQAVDcKcl9u2MfuFj8ekCbeenUn/RjVFfnzseFu31Teb10epOSXayFwTvlbcsbnCxxWc3KG5M9MrAiIwaq50nL48RewPatHhqkD2tfJFK4XwJdgLUYnjT4liSjiprXu7YmLKWWeDtREeQO0w9zwPPkrN8f8kywehepL3/5A+aBC2cPVpo65fomJiKsffGwQRENXQvSPqxG0Hth1yySaRkFMzLZLHnkgWsr339MTDMXduS3aKvqn8bBrjkaQbNTPayfrpI6tsZ7k1bhrLkx49DZ4bkltAtIQ1iCZHQLQFBITbAXCH7CY/LFkahA/ery89CwuNsqXBuJFlLhUBkUObavNEvoWwTSSsVLhtStUgWGClpVrx/NZN88ERf03leMec5YPo6U5uw0I3RJqmYwcX+Mx+rm+pcv3MPhvMSS0CIi+lFq0p8EjPHqXt8gmIgE05bS7Af12oO/zL90ympAaA646Om212mVmprrbi1SBM584dW6fjg+BspWmdsZu+2qXcilhH0ZvqbTY8uvRFJgF+U0gwHNUITe5MuKN17cwJjYIFiekIeTIZC9qgBmG290WM8ah4xKTIoZwVu8//sS/s2aWaMMqY5hgyMTndhN3B8vX0zteJnZTZt7k3WRBzMkH2De0xJn68rOuiupPPWjU+iA4nGaGtfXgLLjmO696EuQ4gGksfqgWfuF+Xu7z5VC0I2Mk8cka0jR0fzaP7UFx7SEBMfbcubvL2q+GO9YU18fxPb3bpB8RN9ewb1fLonx+mJVdqB+209wAvPqqLnpx0va5DYPPJh3VNhZ+drj+PmAIcdbFO9fCX+/Ws51+xg7GKENo8cJWvEZO0g+/Fx4B7vh5975q8SpaAGDYBWHol8BOTCoWFJncerU7Hz4Q+7zkHWP7dyAHMgjZkz/Y5OD9xv9YUph6ho8oOPFmf8weuBWad6N8PM+tEkx4jJXzW5vTf5IsAWvFD4Nnf61nDFJgHYXPMV+JhvUTAKT+JbPOn3gLctFwvH/cNYOMfgcd+mgyhLTUDK38aaa6H/YMWFvM+Ej9eluO7p1v7Xj58oy6YBGS32xYQx1+tU6tPXqiLV9nCqXOqnq3O9/5pt+kghRO+pUPXH7mp4cNcRYPIYux+Oi8/T/J5Y7O2S9tq7HYruqciIAIaRMjsMt/c3FmOXTti6v9MNkzX5uyzg257Ta/nEU7LHjrXUcdkYL/j9Lo5H0zG9I/aS0e8zDD56luHAvNP0w78A5YBh5wZbVvOISCqeYDsrLEHLItGd/seF21j5xMiih7YyYfEi/zwNeEOljt+d5Tojr7tzubAD0c+Ctc56eLzFYzdT4dDNzXp/7vcoo83b2X2SLlthD5+XqYcCow/MHu7ISOjiCb2QaQ5Wud8MLlu38XRSNyugTB/FXCwU7muMtJu1jUZ2NRUagYOXuXRVjLGsPy8zbJScmRNOrT32TZcX9fOaf4aEXa014yj9P81/6NRYADfb3xfp0UxDUAaqzW1hNMEvL5Zd8h2xxELT7VyxPvw1f0FopFSWigpEBcQnC7ZNcH4Hqp3XutdDnz3/Nx92x2q64Owf8dUk/SOr0XFvkvJfbgdPP8v3Tvj7eWOnCPTWJC5Hbmr4YUEfaaJKWfkVX+i4ohP8SekRQC5xLKcUvwYeVNeVwRwwGzmG5CUytnRRH2lEvRg7je+N0WDGKSUWqJMmMMnxjsp2/Fc8UEERjEhAcEd0fYsAbEhWmazkWt28I1qt71W/Wxd3z7TzA+lFiSclYkZu1WcA18LVyil5erh6969I95e3gfbvCvRaE5H7gqIkFCtmJgCHV2eaKN+B3fCKQKi2loGoc44r6Dhjj5kWgvNk0kbDKXdw3kpOcEefB4N5oMQAZGXcqu2ub+y3mgQVif19O26psCf79P2ViAsIEJFZPiGvuOy9PN4ZUP8c6klGdbne/i6t1c3+kucX0oRdsZnYnIf7Dx5+BnuxN3RoH3t3Yc9S4PgjpsFAYex8sRGN9w0JFQr6wOd6UDsKCpVCFPMhNXeQ672F8r3FIIHVKFAhVCurrTBUBGhqPw88P3Gpi7RIAYpe79P3+RDx+q0xa6p5OnbgX9booUIkIynZ97s8k/+4Y7Tzknkw63CNXxi0u4ZGuWN8aTDyIvtXHThDrzcBiy+Inl+ADB+np6Mt+SKaPYwoFNfj95XO7/HzYnWt42I/DX8QB+wXEdbHXpOeATP/0vPrrgw4o5txnuBiQfrQvNAJDA6p2mH/bJrdbrtzunaMR1KBz1pod5mZkpt4/1PAE74Zvj7/sax/wyMmw3smeK7yNOxL/p85JsKmSSzBM2SK4E5HwamHq7/h8X/FH134Apg7kq9bGsQC88C3mtma/MAjX1nNtVmiJ27Us+wtuF28f02am993Y77OhqJmkYxEdFiAFcBKAH4nlLqX5zvLwbAYQtlAPsDGKOUepWIPgXgTOgh2mMAPqaUClSP2Q0c+xX9Yp5xkr3ZE4XaO8M3YfcO3Rm9/HR8fd6R9RumCE3riHBSOH74OF8Qs+zb+Y7hozLT1XPLUJMedZZagCnvAj56K3CjyYnPDvSOybq+AKAjcr5kBOj7vxHfF68fPgnYsi5+zGHjgPMe1svN7VorCk3i6t6hR69NZS0sWGi2DQc+bqVmYBNTc5s+b0AHJSw4Pe1qaGfz+Y+kb3Pyjenf9zcmHwKcc2/6NnlG30deFC1XRtSuBpGxn3f9vX4BwNl/iM/iX/4dYNNDwNofxTWIpV+NlkutOv3Iaf8Z3VOMm4Qzi2XXJtdVNAgjIJrbgLPvqW6/A4CaaRBEVAJwDYAlAGYBOIWIYoV0lVJfVUrNU0rNA3ApgLuNcJgI4DwAC5RSs6EFzIpanWuvcDUIW0A0ldNHWj51uRrbPKALzIT2xQ+xG5GUGaueQpoPoqJBeGYX8zFDNYpD2JFZPnNNZQZrIDW1nb3Wtx3j1lUQ0qk2VXUl/JOduM76avdT+WzuuZAPotwSNve4z0VvcAVEg1JLE9NCAOuVUs8qpXYAuBlAWrD3KQCswssoA2gnojKAIQA89QnriD1TutSSDE9NewB8o/5q6wFwsr00ddmd1NOXYumhKCYgehB9AoIfxlCN4hC24PMdkyeOuW3iY/OIs5zhTG4eos+/CMelkCQh3HOamFxcwcT/Z1BAtIX/8yLqMbhRTA1KLQXERABWDmdsMusSENEQAIsB/BwAlFKbAXwNwEYAXQBeV0rdEfjtWUS0mohWb92aka6gSOyRQ3O7jnCqpAigXgiIausBpBRF4c44T7rivGSZmAB/+glO+5BWRczH8L5qEI6ACAkAIq1FiAZRG9z/Ls9kvDzwoCTkpOaklLVCNIg+4xPTofi54wHcq5R6FQCIqBNa25gOYAKAPYjoVN8PlVLXKaUWKKUWjBmTkYOlSOwbo9yuNQjukGcvT38Aho2Pwi2ZaucoTD5Ev089PPkdd472MULpx/OSy0ndEj8ulaKJUDOOjv+GU3u4zDQzlfewhJvPVMDXv9SM2K3GExjZeZym+TAdU5Kz0YVicOdBVDSIPro/3f/ZZdj4aNa8HRQyKkfOsTwMHafbkJUYcIBTSyf1JgB2opNJCJuJViBuXnofgOeUUlsBgIhuAXA4gJtqcJ69I1YWsV37IEotOl/8MV8BNvwu/Nv2Dp2X/60twNUH6XXVhH8COjrjgseTuWSAaLTO5p2h44BzH0xuVw1pHW2To0F0TtNpJVqHaV/Cp59I+j/Ovscp7Wk4+UYdavrc3db+fSYmK8XBJRtRGXsMGQlc+FT04GZpEICuf1GtiU/Ihyvci9Igho7R/3MoMZ8dkHHRU9oUpXqK+59n/i1wwWM6cKKBqaWAeBDATCKaDmAztBBY6W5ERCMAHAXA1hA2AjjUmJ62AfgbAIFKOHXCTpDXPEQLiO7tunMsldPt/a3DzVR9S6GqVkCUW6MKXS4VATHKOV4f4E7aN8vWDnNlxlpJ4Ny6GoD2nfj8J+VW/fDbM5F9AqJsCQh3spt9XcoZTmqgGKel4KfipOYVvfRB+Ajd/0D8nqjFpEW3Ql+DUjMBoZTaRUTnAvgNdBTSDUqpdUR0tvmeRfwyAHcopd6yfns/Ef0MwMMAdgFYA+C6Wp1rr4hpEG1aQOzakW9CGXd+tt07j4mJSpHNNU2guCamIhLopdnoK07qAu349gPuy28TMzGlUPGLSF7KutDkhLlSzjBXoV9Q039JKfUrAL9y1n3b+fx9AN/3/PaLAL5Yw9PrG3bHxBrErnfymTS487OFSB6Vu70jmlmaJlBYg2BHdsiRVw0VAZGiQRQxKmTsUZ/XxBRwUrvk0SCE3U+DFdZpVGQmdRE0twMb79O5kbLCKgGrCI11+fOE3tnOtlwahIkgKiKaiQWYTxthO2xagrRqyTIxhcJcXfL8H0Lt4HuCfQW1GEwINUOemr5w0vU6D/7vrTQAvhQQH/oB8NNV0edqM32On6tTcNhhe2khfBzmOnofYOnX4qktegtrED4fxMr/AJ76dbEOO9s/4Y1iyqlBZFV+E/Jxxm+Bba9W/7v2DuD4q3SqGgAJU5PQrxEB0Rc4N749i9o1MQ0ZBezl5IOpNnb66EuBH6/IP0LvtooWLfx4dccKkWZiGj4BOOSMYo7D2NcoLYopq+Mv5whzFbLhsOrecPDfRcuVhIA5S5QKdUVMTEVgj6xcJ3VPd9JfUO3oiTvBvAKCfRBFzvKs1GTeTQ+2HRGV5qQWDWKAkSOluNBvEAFRBG9bAqLs2MaVqj6E1SVPpS8bNjEVOctzd5sE7OOlhbnm9kGIgOgXiAYxoBABUQS2BlF2NAjV0/fOteLYy5k6oLsGAqKeI7+siXJplCXMtX8iAmIgIAKiCJY4aYYBa2KZifrpNCkn9rdq5wLAlMOBw87Vy/ss9u9/1ExtLlr0eb3t9CPTz+f4q3TUSJH5hSrlKAuYU1H1sQtwUosPon9w1Gf0fzZudvW/nfMhnSpe2G3IU1MEc08Gnv41sO7WZFps7lBDtQNO/3W0vPInydz1gC6ec1mXXt5vafb5HLxKv4qknqaBVCd1lgaRY+KisPvYaxHwhUBVxSxO+l6x5yJkIhqgMtYnAAAG5UlEQVREUfBIlc07rgbRp333h86tjmGJ3myuOZ3UFZ9Qf7iGgjCwEAFRFGzr7jYJ6CoaRAGzmPvD6LeuGkRWNtcU8mRzFQTBiwiIomABsctUMmtKmXlcLb4wz8FEqpM6Z6oN0SAEoWoGec9TIBPm63euf8Ad0l6LqtvP6H2i5VaPP6JejDBpxScetPuP7RMQnM7bravh266pXH2hekEQxEldGHNXAHvOBvacoz8TAZ98WBcuqYYzf6sT8u18RxeyeWtL8efaGybMA865Dxiz/+4/ti+KqXMqcPa9wNhZye9sZi/XqUqyBIkgCAlEQBQFUSQcmFGBqmlptI3QL6avdRyKZNwB9TluaP7HnjlCJUvN8doUgiDkRkxMQv+nlrWFBUEIIgJC6P9IBJIg1AUREEL/hZ30Ph+EIAg1R4ZmQv/lzDuBp28vtpSpIAi5EQEh9F/G7KtfgiDUBTExCYIgCF5EQAiCIAheREAIgiAIXkRACIIgCF5EQAiCIAheREAIgiAIXkRACIIgCF5EQAiCIAheSNWjQliNIKKtAP7cy5+PBtDLYrkDFmnz4EDaPDjobZunKqXG+L5oKAHRF4hotVJqQb3PY3cibR4cSJsHB7Vos5iYBEEQBC8iIARBEAQvIiAirqv3CdQBafPgQNo8OCi8zeKDEARBELyIBiEIgiB4EQEhCIIgeBn0AoKIFhPRU0S0noguqff5FAUR3UBEW4jocWvdSCK6k4ieMe+d1neXmmvwFBEdW5+z7htENJmIfk9ETxDROiI636xv2HYTURsRPUBEa02bv2zWN2ybGSIqEdEaIvql+dzQbSai54noMSJ6hIhWm3W1bbNSatC+AJQAbAAwA0ALgLUAZtX7vApq25EA5gN43Fp3JYBLzPIlAK4wy7NM21sBTDfXpFTvNvSizeMBzDfLwwA8bdrWsO0GQACGmuVmAPcDOLSR22y1/dMAfgTgl+ZzQ7cZwPMARjvratrmwa5BLASwXin1rFJqB4CbAZxY53MqBKXU/wB41Vl9IoAfmOUfAPiAtf5mpdR2pdRzANZDX5sBhVKqSyn1sFl+E8ATACaigdutNH81H5vNS6GB2wwARDQJwHEAvmetbug2B6hpmwe7gJgI4C/W501mXaMyTinVBejOFMBYs77hrgMRTQNwEPSIuqHbbUwtjwDYAuBOpVTDtxnAvwL4DIAea12jt1kBuIOIHiKis8y6mra53IeTbQTIs24wxv021HUgoqEAfg7gAqXUG0S+5ulNPesGXLuVUt0A5hFRB4BbiWh2yuYDvs1E9H4AW5RSDxHR0Xl+4lk3oNpsOEIp9QIRjQVwJxE9mbJtIW0e7BrEJgCTrc+TALxQp3PZHbxEROMBwLxvMesb5joQUTO0cPihUuoWs7rh2w0ASqnXAPw3gMVo7DYfAeAEInoe2iy8iIhuQmO3GUqpF8z7FgC3QpuMatrmwS4gHgQwk4imE1ELgBUAbqvzOdWS2wCsMsurAPzCWr+CiFqJaDqAmQAeqMP59QnSqsL1AJ5QSn3D+qph201EY4zmACJqB/A+AE+igduslLpUKTVJKTUN+pn9nVLqVDRwm4loDyIaxssAjgHwOGrd5np75uv9ArAUOtplA4DL6n0+BbbrxwC6AOyEHk2cAWAUgLsAPGPeR1rbX2auwVMAltT7/HvZ5ndDq9GPAnjEvJY2crsBHAhgjWnz4wC+YNY3bJud9h+NKIqpYdsMHWm51rzWcV9V6zZLqg1BEATBy2A3MQmCIAgBREAIgiAIXkRACIIgCF5EQAiCIAheREAIgiAIXkRACEIVEFG3yabJr8IyABPRNDv7riDUm8GeakMQqmWbUmpevU9CEHYHokEIQgGYXP1XmNoMDxDR3mb9VCK6i4geNe9TzPpxRHSrqeOwlogON7sqEdF3TW2HO8zsaEGoCyIgBKE62h0T08nWd28opRYC+BZ0tlGY5X9XSh0I4IcArjbrrwZwt1JqLnTdjnVm/UwA1yilDgDwGoCTatweQQgiM6kFoQqI6K9KqaGe9c8DWKSUetYkDHxRKTWKiF4GMF4ptdOs71JKjSairQAmKaW2W/uYBp2ue6b5/I8AmpVSl9e+ZYKQRDQIQSgOFVgObeNju7XcDfETCnVEBIQgFMfJ1vsfzfJ90BlHAeAjAP5glu8CcA5QKfgzfHedpCDkRUYnglAd7aZ6G3O7UopDXVuJ6H7ogdcpZt15AG4goosBbAXwMbP+fADXEdEZ0JrCOdDZdwWh3yA+CEEoAOODWKCUerne5yIIRSEmJkEQBMGLaBCCIAiCF9EgBEEQBC8iIARBEAQvIiAEQRAELyIgBEEQBC8iIARBEAQv/w83kuqx4RwgtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('ANN - model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Loss Function') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Training', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(10, 6), max_iter=150,\n",
      "              random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renug\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(solver='adam',alpha=1e-5,hidden_layer_sizes=(10,6),random_state=1,max_iter=150)\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test using MLP\n",
      "Absolute mean error: 0.21021897810218979\n",
      "Mean square error: 0.21021897810218979\n",
      "Mean square root error: 0.4584964319405221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "print ('\\n Test using MLP')\n",
    "print (\"Absolute mean error:\", metrics.mean_absolute_error(y_test,pred))\n",
    "print (\"Mean square error:\", metrics.mean_squared_error(y_test,pred))\n",
    "print (\"Mean square root error:\", np.sqrt(metrics.mean_squared_error(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[534,   4],\n",
       "       [140,   7]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
